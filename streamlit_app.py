import streamlit as st
import pandas as pd
import plotly.graph_objs as go
import numpy as np
from scipy.stats import t
import re

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´ v2.9", layout="wide")
st.title("ğŸ“Š Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´ v2.9 (ì„ ì •í‘œ ê²€í†  ê¸°ëŠ¥ ê°•í™”)")

# --- ìœ í‹¸ë¦¬í‹° ë° ì „ì—­ ìƒìˆ˜ ---
SERIES_ORDER = ["XRF3", "XRF5", "XRF10", "XRF15", "XRF20", "XRF32", "XRF45", "XRF64", "XRF95", "XRF125", "XRF155", "XRF185", "XRF215", "XRF255"]
STANDARD_MOTORS = [0.75, 1.5, 2.2, 3.7, 5.5, 7.5, 11, 15, 22, 30, 37, 45, 55, 75, 90, 110, 132, 160, 200]

def get_best_match_column(df, names):
    if df is None or df.empty: return None
    for n in names:
        for col in df.columns:
            if n in col.strip():
                return col
    return None

def calculate_efficiency(df, q_col, h_col, k_col):
    if not all(col and col in df.columns for col in [q_col, h_col, k_col]): return df
    df_copy = df.copy()
    hydraulic_power = 0.163 * df_copy[q_col] * df_copy[h_col]
    shaft_power = df_copy[k_col]
    df_copy['Efficiency'] = np.where(shaft_power > 0, (hydraulic_power / shaft_power) * 100, 0)
    return df_copy

def load_sheet(uploaded_file, sheet_name):
    try:
        df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
        df.columns = df.columns.str.strip()
        mcol = get_best_match_column(df, ["ëª¨ë¸ëª…", "ëª¨ë¸", "Model"])
        if not mcol: return None, pd.DataFrame()
        if 'Series' in df.columns: df = df.drop(columns=['Series'])
        
        df['Series'] = df[mcol].astype(str).str.extract(r"(XRF\d+)")
        df['Series'] = pd.Categorical(df['Series'], categories=SERIES_ORDER, ordered=True)
        df = df.sort_values('Series')
        return mcol, df
    except Exception:
        return None, pd.DataFrame()

def process_data(df, q_col, h_col, k_col):
    if df.empty: return df
    temp_df = df.copy()
    for col in [q_col, h_col, k_col]:
        if col and col in temp_df.columns:
            temp_df = temp_df.dropna(subset=[col])
            temp_df = temp_df[pd.to_numeric(temp_df[col], errors='coerce').notna()]
            temp_df[col] = pd.to_numeric(temp_df[col])
    return calculate_efficiency(temp_df, q_col, h_col, k_col)

# --- ë¶„ì„ ë¡œì§ (ë‹¨ì¼/ì†Œë°©/ë°°ì¹˜) ---

def analyze_operating_point(df, models, target_q, target_h, m_col, q_col, h_col, k_col):
    if target_h <= 0: return pd.DataFrame()
    results = []

    if target_q == 0:
        for model in models:
            model_df = df[df[m_col] == model].sort_values(q_col)
            if model_df.empty: continue
            churn_h = model_df.iloc[0][h_col]
            if churn_h >= target_h:
                churn_kw = model_df.iloc[0][k_col] if k_col and k_col in model_df.columns else np.nan
                churn_eff = np.interp(0, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else 0
                results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": "0 (ì²´ì ˆ)", "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{churn_h:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{churn_kw:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{churn_eff:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})
        return pd.DataFrame(results)

    for model in models:
        model_df = df[df[m_col] == model].sort_values(q_col)
        if len(model_df) < 2 or not (model_df[q_col].min() <= target_q <= model_df[q_col].max()): continue
        interp_h = np.interp(target_q, model_df[q_col], model_df[h_col])
        
        if interp_h >= target_h:
            interp_kw = np.interp(target_q, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan
            interp_eff = np.interp(target_q, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else np.nan
            results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": target_q, "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{interp_h:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{interp_eff:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})
        else:
            # ë³´ì • ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ (ì—­ì‚°)
            h_values_rev = model_df[h_col].values[::-1]
            q_values_rev = model_df[q_col].values[::-1]
            if target_h <= model_df[h_col].max() and target_h >= model_df[h_col].min():
                q_required = np.interp(target_h, h_values_rev, q_values_rev)
                if 0.95 * target_q <= q_required < target_q:
                    correction_pct = (1 - (q_required / target_q)) * 100
                    status_text = f"ìœ ëŸ‰ {correction_pct:.1f}% ë³´ì • ì „ì œ ì‚¬ìš© ê°€ëŠ¥"
                    interp_kw_corr = np.interp(q_required, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan
                    interp_eff_corr = np.interp(q_required, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else np.nan
                    results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": target_q, "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{target_h:.2f} (at Q={q_required:.2f})", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw_corr:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{interp_eff_corr:.2f}", "ì„ ì • ê°€ëŠ¥": status_text})
    
    return pd.DataFrame(results)

def analyze_fire_pump_point(df, models, target_q, target_h, m_col, q_col, h_col, k_col):
    if target_q <= 0 or target_h <= 0: return pd.DataFrame()
    results = []
    for model in models:
        model_df = df[df[m_col] == model].sort_values(q_col)
        if len(model_df) < 2: continue
        
        res_dict = _batch_analyze_fire_point(model_df, target_q, target_h, q_col, h_col, k_col, STANDARD_MOTORS)
        
        row = {
            "ëª¨ë¸ëª…": model,
            "ì •ê²© ì˜ˆìƒ ì–‘ì •": res_dict['ì •ê²© ì˜ˆìƒ ì–‘ì •'],
            "ì²´ì ˆ ì–‘ì • (ì˜ˆìƒ)": res_dict['ì²´ì ˆ ì–‘ì • (ì˜ˆìƒ)'],
            "ì²´ì ˆ ì–‘ì • (ê¸°ì¤€)": res_dict['ì²´ì ˆ ì–‘ì • (ê¸°ì¤€)'],
            "ìµœëŒ€ìš´ì „ ì–‘ì • (ì˜ˆìƒ)": res_dict['ìµœëŒ€ìš´ì „ ì–‘ì • (ì˜ˆìƒ)'],
            "ìµœëŒ€ìš´ì „ ì–‘ì • (ê¸°ì¤€)": res_dict['ìµœëŒ€ìš´ì „ ì–‘ì • (ê¸°ì¤€)'],
            "ì˜ˆìƒ ë™ë ¥(kW)": f"{res_dict['ì •ê²© ë™ë ¥(kW)']:.2f}",
            "ì„ ì • ê°€ëŠ¥": res_dict['ì„ ì • ê°€ëŠ¥']
        }
        results.append(row)
        
    return pd.DataFrame(results)

def _calculate_motor(p_rated, p_overload, standard_motors):
    if pd.isna(p_rated) or pd.isna(p_overload):
        return np.nan
    for motor_kw in standard_motors:
        if (p_rated <= motor_kw * 1.05) and (p_overload <= motor_kw * 1.15):
            return motor_kw
    return np.nan

def _batch_analyze_fire_point(model_df, target_q, target_h, q_col, h_col, k_col, standard_motors):
    if target_q <= 0 or target_h <= 0: 
        return {
            "ì„ ì • ê°€ëŠ¥": "âŒ ì‚¬ìš© ë¶ˆê°€", "ìƒì„¸": "ìœ ëŸ‰/ì–‘ì • 0",
            "ì •ê²© ì˜ˆìƒ ì–‘ì •": "N/A", "ì²´ì ˆ ì–‘ì • (ì˜ˆìƒ)": "N/A", "ì²´ì ˆ ì–‘ì • (ê¸°ì¤€)": "N/A",
            "ìµœëŒ€ìš´ì „ ì–‘ì • (ì˜ˆìƒ)": "N/A", "ìµœëŒ€ìš´ì „ ì–‘ì • (ê¸°ì¤€)": "N/A", 
            "ì •ê²© ë™ë ¥(kW)": np.nan, "ìµœëŒ€ ë™ë ¥(kW)": np.nan, "ì„ ì • ëª¨í„°(kW)": np.nan,
            "ë³´ì •ë¥ (%)": 0.0, "ë™ë ¥ì´ˆê³¼(100%)": 0.0, "ë™ë ¥ì´ˆê³¼(150%)": 0.0
        }
    
    h_churn_limit = 1.40 * target_h
    h_overload_limit = 0.65 * target_h
    h_churn = model_df.iloc[0][h_col]
    TOLERANCE_FACTOR = 0.97 

    correction_steps = np.linspace(0, 0.05, 51) 
    
    for correction_pct in correction_steps:
        q_corrected = target_q * (1 - correction_pct)
        interp_h_rated = np.interp(q_corrected, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)
        q_overload_corr = 1.5 * q_corrected
        interp_h_overload_corr = np.interp(q_overload_corr, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)
        
        p_corr = np.interp(q_corrected, model_df[q_col], model_df[k_col], left=np.nan, right=np.nan)
        p_overload_corr = np.interp(q_overload_corr, model_df[q_col], model_df[k_col], left=np.nan, right=np.nan)
        
        cond_rated = (not np.isnan(interp_h_rated)) and (interp_h_rated >= target_h)
        cond_churn = (h_churn <= h_churn_limit)
        cond_overload = (not np.isnan(interp_h_overload_corr)) and (interp_h_overload_corr >= h_overload_limit * TOLERANCE_FACTOR)
        
        if cond_rated and cond_churn and cond_overload:
            motor_corr = _calculate_motor(p_corr, p_overload_corr, standard_motors)
            p_ratio_100 = (p_corr / motor_corr * 100) if motor_corr and not pd.isna(motor_corr) else 0.0
            p_ratio_150 = (p_overload_corr / motor_corr * 100) if motor_corr and not pd.isna(motor_corr) else 0.0

            if correction_pct == 0:
                status_text = "âœ…"
                detail_text = "ì •ê²© ìœ ëŸ‰ ê¸°ì¤€"
            else:
                status_text = f"âš ï¸ ë³´ì • í•„ìš”"
                detail_text = f"ìœ ëŸ‰ {correction_pct*100:.1f}% ë³´ì •"
            
            return {
                "ì •ê²© ì˜ˆìƒ ì–‘ì •": f"{interp_h_rated:.2f}",
                "ì²´ì ˆ ì–‘ì • (ì˜ˆìƒ)": f"{h_churn:.2f}",
                "ì²´ì ˆ ì–‘ì • (ê¸°ì¤€)": f"â‰¤{h_churn_limit:.2f}",
                "ìµœëŒ€ìš´ì „ ì–‘ì • (ì˜ˆìƒ)": f"{interp_h_overload_corr:.2f}",
                "ìµœëŒ€ìš´ì „ ì–‘ì • (ê¸°ì¤€)": f"â‰¥{h_overload_limit:.2f}",
                "ì •ê²© ë™ë ¥(kW)": p_corr,
                "ìµœëŒ€ ë™ë ¥(kW)": p_overload_corr,
                "ì„ ì • ëª¨í„°(kW)": motor_corr,
                "ì„ ì • ê°€ëŠ¥": status_text,
                "ìƒì„¸": detail_text,
                "ë³´ì •ë¥ (%)": correction_pct * 100,
                "ë™ë ¥ì´ˆê³¼(100%)": p_ratio_100,
                "ë™ë ¥ì´ˆê³¼(150%)": p_ratio_150
            }

    # ì‹¤íŒ¨ ì‹œ ì›ì¸ ë¶„ì„
    q_orig = target_q
    interp_h_orig = np.interp(q_orig, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)
    q_over_orig = 1.5 * q_orig
    interp_h_over_orig = np.interp(q_over_orig, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)
    
    fail_reason = ""
    if np.isnan(interp_h_orig) or interp_h_orig < target_h: fail_reason = "ì •ê²© ì–‘ì • ë¯¸ë‹¬"
    elif h_churn > h_churn_limit: fail_reason = "ì²´ì ˆ ì–‘ì • ì´ˆê³¼"
    elif np.isnan(interp_h_over_orig) or interp_h_over_orig < h_overload_limit * TOLERANCE_FACTOR: fail_reason = "ìµœëŒ€ ìš´ì „ ì–‘ì • ë¯¸ë‹¬"
    else: fail_reason = "3ì  ê¸°ì¤€ ë¯¸ë‹¬"

    return {
        "ì •ê²© ì˜ˆìƒ ì–‘ì •": f"{interp_h_orig:.2f}",
        "ì²´ì ˆ ì–‘ì • (ì˜ˆìƒ)": f"{h_churn:.2f}",
        "ì²´ì ˆ ì–‘ì • (ê¸°ì¤€)": f"â‰¤{h_churn_limit:.2f}",
        "ìµœëŒ€ìš´ì „ ì–‘ì • (ì˜ˆìƒ)": f"{interp_h_over_orig:.2f}",
        "ìµœëŒ€ìš´ì „ ì–‘ì • (ê¸°ì¤€)": f"â‰¥{h_overload_limit:.2f}",
        "ì •ê²© ë™ë ¥(kW)": np.nan, "ìµœëŒ€ ë™ë ¥(kW)": np.nan, "ì„ ì • ëª¨í„°(kW)": np.nan,
        "ì„ ì • ê°€ëŠ¥": "âŒ ì‚¬ìš© ë¶ˆê°€",
        "ìƒì„¸": fail_reason,
        "ë³´ì •ë¥ (%)": 0.0, "ë™ë ¥ì´ˆê³¼(100%)": 0.0, "ë™ë ¥ì´ˆê³¼(150%)": 0.0
    }

def find_recommendation(df_r, m_r, q_col, h_col, k_col, target_q, target_h, assigned_model):
    # í˜„ì¬ ì‹œë¦¬ì¦ˆ íŒŒì•… ë° ê²€ìƒ‰ ë²”ìœ„ ì¶•ì†Œ
    match = re.search(r"(XRF\d+)", str(assigned_model))
    target_series_subset = []
    
    if match:
        current_series = match.group(1)
        if current_series in SERIES_ORDER:
            curr_idx = SERIES_ORDER.index(current_series)
            start_idx = max(0, curr_idx - 2) # ì´ì „ 2ê°œ ì‹œë¦¬ì¦ˆë¶€í„° ê²€ìƒ‰
            target_series_subset = SERIES_ORDER[start_idx:]
    
    if target_series_subset:
        candidate_models = df_r[df_r['Series'].isin(target_series_subset)][m_r].unique()
    else:
        candidate_models = df_r[m_r].unique()

    candidates = []

    for model in candidate_models:
        if model == assigned_model: continue
        
        model_df = df_r[df_r[m_r] == model].sort_values(q_col)
        if model_df.empty: continue
        
        # ëŒ€ëµì ì¸ ë²”ìœ„ í•„í„°ë§ (ì†ë„ í–¥ìƒ)
        if not (model_df[q_col].max() * 1.1 >= target_q and model_df[h_col].max() >= target_h):
            continue

        res = _batch_analyze_fire_point(model_df, target_q, target_h, q_col, h_col, k_col, STANDARD_MOTORS)
        
        if "âŒ" not in res['ì„ ì • ê°€ëŠ¥']:
            candidates.append({
                "ëª¨ë¸ëª…": model,
                "ë³´ì •ë¥ ": res['ë³´ì •ë¥ (%)'],
                "ëª¨í„°": res['ì„ ì • ëª¨í„°(kW)']
            })
    
    if not candidates: return None
    
    # ë³´ì •ë¥  ë‚®ì€ ìˆœ, ëª¨í„° ìš©ëŸ‰ ì‘ì€ ìˆœ ì •ë ¬
    candidates.sort(key=lambda x: (x['ë³´ì •ë¥ '], x['ëª¨í„°']))
    
    best = candidates[0]
    rec_str = f"{best['ëª¨ë¸ëª…']} ({best['ë³´ì •ë¥ ']:.1f}% ë³´ì •)" if best['ë³´ì •ë¥ '] > 0 else best['ëª¨ë¸ëª…']
    return rec_str

def render_filters(df, mcol, prefix):
    if df is None or df.empty or mcol is None or 'Series' not in df.columns:
        st.warning("í•„í„°ë§í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    series_opts = df['Series'].dropna().unique().tolist()
    default_series = [series_opts[0]] if series_opts else []
    mode = st.radio("ë¶„ë¥˜ ê¸°ì¤€", ["ì‹œë¦¬ì¦ˆë³„", "ëª¨ë¸ë³„"], key=f"{prefix}_mode", horizontal=True)
    if mode == "ì‹œë¦¬ì¦ˆë³„":
        sel = st.multiselect("ì‹œë¦¬ì¦ˆ ì„ íƒ", series_opts, default=default_series, key=f"{prefix}_series")
        df_f = df[df['Series'].isin(sel)] if sel else pd.DataFrame()
    else:
        model_opts = df[mcol].dropna().unique().tolist()
        default_model = [model_opts[0]] if model_opts else []
        sel = st.multiselect("ëª¨ë¸ ì„ íƒ", model_opts, default=default_model, key=f"{prefix}_models")
        df_f = df[df[mcol].isin(sel)] if sel else pd.DataFrame()
    return df_f

def parse_selection_table(df_selection_table):
    try:
        q_col_indices = list(range(4, df_selection_table.shape[1], 3))
        h_row_indices = list(range(15, df_selection_table.shape[0], 3))
        
        tasks = []
        q_values = {}
        h_values = {}

        # Q íŒŒì‹±
        for c_idx in q_col_indices:
            q_val_raw = str(df_selection_table.iloc[10, c_idx])
            if pd.isna(q_val_raw) or q_val_raw == "": continue
            try:
                q_val_clean = q_val_raw.split('(')[0].strip()
                q_values[c_idx] = float(q_val_clean)
            except (ValueError, TypeError):
                continue 
        
        # H íŒŒì‹±
        for r_idx in h_row_indices:
            h_val_raw = str(df_selection_table.iloc[r_idx, 1])
            if pd.isna(h_val_raw) or h_val_raw == "": continue
            try:
                h_val_clean = h_val_raw.split('\n')[0].split('(')[0].strip()
                h_values[r_idx] = float(h_val_clean)
            except (ValueError, TypeError):
                continue 
        
        # êµì°¨ ì§€ì  íŒŒì‹± (ì™„ì „ íƒìƒ‰)
        for r_idx in h_values:
            for c_idx in q_values:
                raw_cell = df_selection_table.iloc[r_idx, c_idx]
                model_name = str(raw_cell).strip()
                
                # XRF í¬í•¨ ì—¬ë¶€ë¡œ ëª¨ë¸ íŒë‹¨, ì•„ë‹ˆë©´ ë¯¸ì„ ì •
                if "XRF" in model_name:
                    pass
                else:
                    model_name = "ë¯¸ì„ ì •"
                
                tasks.append({
                    "ëª¨ë¸ëª…": model_name,
                    "ìš”êµ¬ ìœ ëŸ‰ (Q)": q_values[c_idx],
                    "ìš”êµ¬ ì–‘ì • (H)": h_values[r_idx],
                    "_source_cell": f"[Row {r_idx + 1}, Col {chr(65 + c_idx)}]"
                })
        
        return pd.DataFrame(tasks)
    
    except Exception as e:
        st.error(f"ì„ ì •í‘œ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return pd.DataFrame()

# --- ì‹œê°í™” í•¨ìˆ˜ ---
def add_traces(fig, df, mcol, xcol, ycol, models, mode, line_style=None, name_suffix=""):
    for m in models:
        sub = df[df[mcol] == m].sort_values(xcol)
        if sub.empty or ycol not in sub.columns: continue
        fig.add_trace(go.Scatter(x=sub[xcol], y=sub[ycol], mode=mode, name=m + name_suffix, line=line_style or {}))

def add_bep_markers(fig, df, mcol, qcol, ycol, models):
    for m in models:
        model_df = df[df[mcol] == m]
        if not model_df.empty and 'Efficiency' in model_df.columns and not model_df['Efficiency'].isnull().all():
            bep_row = model_df.loc[model_df['Efficiency'].idxmax()]
            fig.add_trace(go.Scatter(x=[bep_row[qcol]], y=[bep_row[ycol]], mode='markers', marker=dict(symbol='star', size=15, color='gold'), name=f'{m} BEP'))

def add_guide_lines(fig, h_line, v_line):
    if h_line is not None and h_line > 0:
        fig.add_shape(type="line", x0=0, x1=1, xref="paper", y0=h_line, y1=h_line, yref="y", line=dict(color="gray", dash="dash"))
    if v_line is not None and v_line > 0:
        fig.add_shape(type="line", x0=v_line, x1=v_line, xref="x", y0=0, y1=1, yref="paper", line=dict(color="gray", dash="dash"))

def render_chart(fig, key):
    fig.update_layout(dragmode='pan', xaxis=dict(fixedrange=False), yaxis=dict(fixedrange=False), legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))
    st.plotly_chart(fig, use_container_width=True, config={'scrollZoom': True, 'displaylogo': False}, key=key)

def perform_validation_analysis(df_r, df_d, m_r, m_d, q_r, q_d, y_r_col, y_d_col, test_id_col, models_to_validate, analysis_type):
    all_results = {}
    for model in models_to_validate:
        model_summary = []
        model_r_df = df_r[(df_r[m_r] == model) & (df_r[y_r_col].notna())].sort_values(by=q_r)
        model_d_df = df_d[(df_d[m_d] == model) & (df_d[y_d_col].notna())]
        if model_r_df.empty or model_d_df.empty: continue
        
        max_q = model_r_df[q_r].max()
        validation_q = np.linspace(0, max_q, 10)
        ref_y = np.interp(validation_q, model_r_df[q_r], model_r_df[y_r_col])
        test_ids = model_d_df[test_id_col].unique()
        interpolated_y_samples = {q: [] for q in validation_q}
        for test_id in test_ids:
            test_df = model_d_df[model_d_df[test_id_col] == test_id].sort_values(by=q_d)
            if len(test_df) < 2: continue
            interp_y = np.interp(validation_q, test_df[q_d], test_df[y_d_col])
            for i, q in enumerate(validation_q):
                interpolated_y_samples[q].append(interp_y[i])
        
        for i, q in enumerate(validation_q):
            samples = np.array(interpolated_y_samples[q])
            n = len(samples)
            base_col_name = f"ê¸°ì¤€ {analysis_type}"
            mean_col_name = "í‰ê· "
            if n < 2:
                model_summary.append({
                    "ëª¨ë¸ëª…": model, "ê²€ì¦ ìœ ëŸ‰(Q)": q, base_col_name: ref_y[i], 
                    "ì‹œí—˜ íšŸìˆ˜(n)": n, mean_col_name: np.nan, "í‘œì¤€í¸ì°¨": np.nan, 
                    "95% CI í•˜í•œ": np.nan, "95% CI ìƒí•œ": np.nan, "ìœ íš¨ì„±": "íŒë‹¨ë¶ˆê°€",
                    "_original_q": q
                })
                continue
            
            mean_y, std_dev = np.mean(samples), np.std(samples, ddof=1)
            std_err = std_dev / np.sqrt(n)
            t_critical = t.ppf(0.975, df=n-1)
            margin_of_error = t_critical * std_err
            ci_lower, ci_upper = mean_y - margin_of_error, mean_y + margin_of_error
            is_valid = "âœ… ìœ íš¨" if ci_lower <= ref_y[i] <= ci_upper else "âŒ ë²—ì–´ë‚¨"
            
            model_summary.append({
                "ëª¨ë¸ëª…": model, "ê²€ì¦ ìœ ëŸ‰(Q)": f"{q:.2f}", base_col_name: f"{ref_y[i]:.2f}",
                "ì‹œí—˜ íšŸìˆ˜(n)": n, mean_col_name: f"{mean_y:.2f}", "í‘œì¤€í¸ì°¨": f"{std_dev:.2f}",
                "95% CI í•˜í•œ": f"{ci_lower:.2f}", "95% CI ìƒí•œ": f"{ci_upper:.2f}", "ìœ íš¨ì„±": is_valid,
                "_original_q": q
            })
        
        all_results[model] = { 'summary': pd.DataFrame(model_summary), 'samples': interpolated_y_samples }
    return all_results

# --- ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ---
uploaded_file = st.file_uploader("1. ê¸°ì¤€ ë°ì´í„° Excel íŒŒì¼ ì—…ë¡œë“œ (reference data ì‹œíŠ¸ í¬í•¨)", type=["xlsx", "xlsm"])
if uploaded_file:
    m_r, df_r_orig = load_sheet(uploaded_file, "reference data"); m_c, df_c_orig = load_sheet(uploaded_file, "catalog data"); m_d, df_d_orig = load_sheet(uploaded_file, "deviation data")
    if df_r_orig.empty: st.error("ì˜¤ë¥˜: 'reference data' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ 'ëª¨ë¸ëª…' ê´€ë ¨ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.sidebar.title("âš™ï¸ ë¶„ì„ ì„¤ì •")
        all_columns_r = df_r_orig.columns.tolist()
        def safe_get_index(items, value, default=0):
            try: return items.index(value)
            except (ValueError, TypeError): return default
        q_auto_r = get_best_match_column(df_r_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]); h_auto_r = get_best_match_column(df_r_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]); k_auto_r = get_best_match_column(df_r_orig, ["ì¶•ë™ë ¥"])
        q_col_total = st.sidebar.selectbox("ìœ ëŸ‰ (Flow) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, q_auto_r))
        h_col_total = st.sidebar.selectbox("ì–‘ì • (Head) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, h_auto_r))
        k_col_total = st.sidebar.selectbox("ì¶•ë™ë ¥ (Power) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, k_auto_r))
        q_c, h_c, k_c = (get_best_match_column(df_c_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]), get_best_match_column(df_c_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]), get_best_match_column(df_c_orig, ["ì¶•ë™ë ¥"]))
        q_d, h_d, k_d = (get_best_match_column(df_d_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]), get_best_match_column(df_d_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]), get_best_match_column(df_d_orig, ["ì¶•ë™ë ¥"]))
        test_id_col_d = get_best_match_column(df_d_orig, ["ì‹œí—˜ë²ˆí˜¸", "Test No", "Test ID"])
        if not df_d_orig.empty and test_id_col_d:
            df_d_orig[test_id_col_d] = df_d_orig[test_id_col_d].astype(str).str.strip().replace(['', 'nan'], np.nan).ffill()
        df_r = process_data(df_r_orig, q_col_total, h_col_total, k_col_total); df_c = process_data(df_c_orig, q_c, h_c, k_c); df_d = process_data(df_d_orig, q_d, h_d, k_d)
        
        tab_list = ["Total", "Reference", "Catalog", "Deviation", "Validation", "ğŸ”¥ ì„ ì •í‘œ ê²€í†  (AI)"]
        tabs = st.tabs(tab_list)
        
        # [Total íƒ­]
        with tabs[0]:
            st.subheader("ğŸ“Š Total - í†µí•© ê³¡ì„  ë° ìš´ì „ì  ë¶„ì„")
            df_f = render_filters(df_r, m_r, "total")
            models = df_f[m_r].unique().tolist() if m_r and not df_f.empty else []
            
            with st.expander("ìš´ì „ì  ë¶„ì„ (Operating Point Analysis)"):
                analysis_mode = st.radio("ë¶„ì„ ëª¨ë“œ", ["ê¸°ê³„", "ì†Œë°©"], key="analysis_mode", horizontal=True)
                op_col1, op_col2 = st.columns(2)
                with op_col1:
                    target_q = float(st.text_input("ëª©í‘œ ìœ ëŸ‰ (Q, mÂ³/min)", value="0.0"))
                with op_col2:
                    target_h = float(st.text_input("ëª©í‘œ ì–‘ì • (H, m)", value="0.0"))
                
                if st.button("ëª¨ë¸ ê²€ìƒ‰ ì‹¤í–‰"):
                    if not models: st.warning("ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    else:
                        if analysis_mode == "ì†Œë°©": op_results_df = analyze_fire_pump_point(df_r, models, target_q, target_h, m_r, q_col_total, h_col_total, k_col_total)
                        else: op_results_df = analyze_operating_point(df_r, models, target_q, target_h, m_r, q_col_total, h_col_total, k_col_total)
                        st.dataframe(op_results_df, use_container_width=True)

                st.markdown("---")
                st.markdown("#### ğŸ“¥ ëª¨ë¸ë³„ ê°œë³„ ìš´ì „ì  ê²€í†  (Batch)")
                if 'batch_df' not in st.session_state:
                    st.session_state.batch_df = pd.DataFrame([{"ëª¨ë¸ëª…": "XRF5-16", "ìš”êµ¬ ìœ ëŸ‰ (Q)": 0.06, "ìš”êµ¬ ì–‘ì • (H)": 35.0, "ë¶„ì„ ëª¨ë“œ": "ê¸°ê³„"}])
                
                edited_df = st.data_editor(st.session_state.batch_df, num_rows="dynamic", use_container_width=True, key="batch_editor")
                st.session_state.batch_df = edited_df
                
                if st.button("ğŸš€ ê°œë³„ ëª¨ë¸ ê²€í†  ì‹¤í–‰"):
                    results = []
                    for _, row in edited_df.iterrows():
                        model, q, h, mode = row['ëª¨ë¸ëª…'], row['ìš”êµ¬ ìœ ëŸ‰ (Q)'], row['ìš”êµ¬ ì–‘ì • (H)'], row['ë¶„ì„ ëª¨ë“œ']
                        if not model or model not in df_r[m_r].unique(): continue
                        if mode == "ì†Œë°©": res_df = analyze_fire_pump_point(df_r, [model], q, h, m_r, q_col_total, h_col_total, k_col_total)
                        else: res_df = analyze_operating_point(df_r, [model], q, h, m_r, q_col_total, h_col_total, k_col_total)
                        if not res_df.empty:
                            res_row = res_df.iloc[0]
                            results.append({'ëª¨ë¸ëª…': model, 'ìš”êµ¬ ìœ ëŸ‰ (Q)': q, 'ìš”êµ¬ ì–‘ì • (H)': h, 'ë¶„ì„ ëª¨ë“œ': mode, 'ê²°ê³¼': res_row['ì„ ì • ê°€ëŠ¥'], 'ìƒì„¸': str(res_row.to_dict())})
                    st.session_state.batch_results_df = pd.DataFrame(results)

                if 'batch_results_df' in st.session_state and not st.session_state.batch_results_df.empty:
                    st.dataframe(st.session_state.batch_results_df, use_container_width=True)

            st.markdown("---")
            ref_show, cat_show, dev_show = st.checkbox("Reference", True), st.checkbox("Catalog"), st.checkbox("Deviation")
            fig_h = go.Figure()
            if ref_show and not df_f.empty: add_traces(fig_h, df_f, m_r, q_col_total, h_col_total, models, 'lines+markers'); add_bep_markers(fig_h, df_f, m_r, q_col_total, h_col_total, models)
            if cat_show and not df_c.empty: add_traces(fig_h, df_c, m_c, q_c, h_c, models, 'lines+markers', line_style=dict(dash='dot'))
            if dev_show and not df_d.empty: add_traces(fig_h, df_d, m_d, q_d, h_d, models, 'markers')
            render_chart(fig_h, "total_qh")

        # [ê¸°ë³¸ ë°ì´í„° íƒ­ë“¤]
        for idx, sheet_name in enumerate(["Reference", "Catalog", "Deviation"]):
            with tabs[idx+1]:
                df, mcol = (df_r, m_r) if sheet_name == "Reference" else (df_c, m_c) if sheet_name == "Catalog" else (df_d, m_d)
                if df.empty: st.info("ë°ì´í„° ì—†ìŒ"); continue
                df_f_tab = render_filters(df, mcol, sheet_name)
                models_tab = df_f_tab[mcol].unique().tolist()
                if not models_tab: continue
                mode, style = ('markers', None) if sheet_name == "Deviation" else ('lines+markers', dict(dash='dot') if sheet_name == "Catalog" else None)
                q_col_tab = get_best_match_column(df_r_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]) # ì„ì‹œ: íƒ­ë³„ ì»¬ëŸ¼ ë§¤í•‘ ë‹¨ìˆœí™”
                h_col_tab = get_best_match_column(df_r_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"])
                fig1 = go.Figure(); add_traces(fig1, df_f_tab, mcol, q_col_tab, h_col_tab, models_tab, mode, line_style=style); render_chart(fig1, f"{sheet_name}_qh")

        # [Validation íƒ­]
        with tabs[4]:
            st.subheader("ğŸ”¬ Reference Data í†µê³„ì  ìœ íš¨ì„± ê²€ì¦")
            common_models = sorted(list(set(df_r[m_r].unique()) & set(df_d[m_d].unique())))
            models_to_validate = st.multiselect("ê²€ì¦í•  ëª¨ë¸ ì„ íƒ", common_models)
            if st.button("ğŸ“ˆ í†µê³„ ê²€ì¦ ì‹¤í–‰") and models_to_validate:
                head_results = perform_validation_analysis(df_r, df_d, m_r, m_d, q_col_total, q_d, h_col_total, h_d, test_id_col_d, models_to_validate, "ì–‘ì •")
                for model in models_to_validate:
                    st.markdown(f"### {model}")
                    st.dataframe(head_results[model]['summary'], use_container_width=True)

        # [AI ì„ ì •í‘œ ê²€í†  íƒ­]
        with tabs[5]:
            st.subheader("ğŸ”¥ XRF ëª¨ë¸ ì„ ì •í‘œ ìë™ ê²€í†  (AI)")
            if df_r.empty: st.error("Reference dataê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            else:
                review_excel_file = st.file_uploader("2. ì„ ì •í‘œ Excel íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xlsm"], key="review_excel")
                if review_excel_file:
                    try:
                        df_selection_excel = pd.read_excel(review_excel_file, header=None)
                    except:
                        st.error("íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨")
                        df_selection_excel = None

                    if df_selection_excel is not None:
                        if 'task_list_df' not in st.session_state or st.session_state.get('review_file_name') != review_excel_file.name:
                             st.session_state.task_list_df = parse_selection_table(df_selection_excel)
                             st.session_state.review_file_name = review_excel_file.name
                        
                        task_df = st.session_state.task_list_df
                        if task_df.empty: st.error("ìœ íš¨í•œ ê²€í†  ëŒ€ìƒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        else:
                            st.markdown(f"ì´ {len(task_df)}ê°œ ê²€í†  ëŒ€ìƒ ë°œê²¬")
                            
                            if st.button("ğŸš€ ì†Œë°© ì„±ëŠ¥ ê¸°ì¤€ ê²€í†  ì‹¤í–‰"):
                                results = []
                                grouped_tasks = task_df.groupby('ëª¨ë¸ëª…')
                                for model_name, tasks in grouped_tasks:
                                    if model_name == "ë¯¸ì„ ì •":
                                        for _, row in tasks.iterrows():
                                            results.append({"ì„ ì • ëª¨ë¸": "ë¯¸ì„ ì •", "ìš”êµ¬ ìœ ëŸ‰(Q)": row['ìš”êµ¬ ìœ ëŸ‰ (Q)'], "ìš”êµ¬ ì–‘ì •(H)": row['ìš”êµ¬ ì–‘ì • (H)'], "ê²°ê³¼": "âŒ ì„ ì • ë¶ˆê°€", "ì¶”ì²œëª¨ë¸": ""})
                                        continue
                                    
                                    if model_name not in df_r[m_r].unique():
                                        for _, row in tasks.iterrows():
                                            results.append({"ì„ ì • ëª¨ë¸": model_name, "ìš”êµ¬ ìœ ëŸ‰(Q)": row['ìš”êµ¬ ìœ ëŸ‰ (Q)'], "ìš”êµ¬ ì–‘ì •(H)": row['ìš”êµ¬ ì–‘ì • (H)'], "ê²°ê³¼": "âŒ ëª¨ë¸ ì—†ìŒ", "ì¶”ì²œëª¨ë¸": ""})
                                        continue

                                    model_df = df_r[df_r[m_r] == model_name].sort_values(q_col_total)
                                    for _, row in tasks.iterrows():
                                        res = _batch_analyze_fire_point(model_df, row['ìš”êµ¬ ìœ ëŸ‰ (Q)'], row['ìš”êµ¬ ì–‘ì • (H)'], q_col_total, h_col_total, k_col_total, STANDARD_MOTORS)
                                        results.append({
                                            "ì„ ì • ëª¨ë¸": model_name, "ìš”êµ¬ ìœ ëŸ‰(Q)": row['ìš”êµ¬ ìœ ëŸ‰ (Q)'], "ìš”êµ¬ ì–‘ì •(H)": row['ìš”êµ¬ ì–‘ì • (H)'], 
                                            "ê²°ê³¼": res['ì„ ì • ê°€ëŠ¥'], "ì„ ì • ëª¨í„°(kW)": res['ì„ ì • ëª¨í„°(kW)'], "ë³´ì •ë¥ (%)": res['ë³´ì •ë¥ (%)'], 
                                            "ë™ë ¥ì´ˆê³¼(100%)": res['ë™ë ¥ì´ˆê³¼(100%)'], "ë™ë ¥ì´ˆê³¼(150%)": res['ë™ë ¥ì´ˆê³¼(150%)'], "ì¶”ì²œëª¨ë¸": ""
                                        })
                                st.session_state.review_results_df = pd.DataFrame(results)
                                st.rerun()

                if 'review_results_df' in st.session_state:
                    st.markdown("---")
                    results_df = st.session_state.review_results_df
                    
                    if st.button("ğŸ•µï¸ ëŒ€ì•ˆ ëª¨ë¸ ì¶”ì²œ ì‹¤í–‰"):
                        with st.spinner("ìµœì  ëª¨ë¸ íƒìƒ‰ ì¤‘..."):
                            for idx, row in results_df.iterrows():
                                if "âœ…" in row['ê²°ê³¼']: continue
                                rec_str = find_recommendation(df_r, m_r, q_col_total, h_col_total, k_col_total, row['ìš”êµ¬ ìœ ëŸ‰(Q)'], row['ìš”êµ¬ ì–‘ì •(H)'], row['ì„ ì • ëª¨ë¸'])
                                results_df.at[idx, 'ì¶”ì²œëª¨ë¸'] = rec_str if rec_str else "ëŒ€ì•ˆ ì—†ìŒ"
                            st.session_state.review_results_df = results_df
                            st.success("ì¶”ì²œ ì™„ë£Œ!")
                            st.rerun()

                    st.markdown("#### âœ… ì „ì²´ ê²€í†  ê²°ê³¼ (í”¼ë²— í…Œì´ë¸”)")
                    if results_df.empty: st.info("ê²°ê³¼ ì—†ìŒ")
                    else:
                        def format_motor(kw):
                            if pd.isna(kw): return "(?kW)"
                            return f"({int(kw)}kW)" if kw == int(kw) else f"({kw}kW)"

                        def create_display_text(row):
                            model_val = row['ì„ ì • ëª¨ë¸']
                            rec_val = row.get('ì¶”ì²œëª¨ë¸', '')
                            
                            # [ìˆ˜ì •ë¨] ë¯¸ì„ ì • ê³µë€ ì²˜ë¦¬ ë¡œì§
                            if model_val == "ë¯¸ì„ ì •":
                                base_text = "âŒ ì„ ì •ë¶ˆê°€"
                                if rec_val == "ëŒ€ì•ˆ ì—†ìŒ": return base_text + "\n(ëŒ€ì•ˆëª¨ë¸ ì—†ìŒ)"
                                elif rec_val: return base_text + f"\nğŸ’¡ ì¶”ì²œ: {rec_val}"
                                else: return base_text
                            
                            base_text = f"{model_val} {format_motor(row.get('ì„ ì • ëª¨í„°(kW)', np.nan))}"
                            if "âŒ" in str(row['ê²°ê³¼']): base_text = f"âŒ {base_text}"
                            
                            extras = []
                            if row.get('ë³´ì •ë¥ (%)', 0) > 0: extras.append(f"ğŸ’§ ë³´ì •:{row['ë³´ì •ë¥ (%)']:.1f}%")
                            p_max = max(row.get('ë™ë ¥ì´ˆê³¼(100%)', 0), row.get('ë™ë ¥ì´ˆê³¼(150%)', 0))
                            if p_max > 100: extras.append(f"âš¡ ì´ˆê³¼:{p_max:.0f}%")
                            
                            if rec_val == "ëŒ€ì•ˆ ì—†ìŒ": extras.append("(ëŒ€ì•ˆëª¨ë¸ ì—†ìŒ)")
                            elif rec_val: extras.append(f"ğŸ’¡ ì¶”ì²œ: {rec_val}")
                            
                            return base_text + ("\n" + "\n".join(extras) if extras else "")

                        results_df['í‘œì‹œê°’'] = results_df.apply(create_display_text, axis=1)
                        
                        try:
                            pivot_df = pd.pivot_table(
                                results_df, values='í‘œì‹œê°’', index='ìš”êµ¬ ì–‘ì •(H)', columns='ìš”êµ¬ ìœ ëŸ‰(Q)', 
                                aggfunc='first', fill_value="âŒ ì„ ì •ë¶ˆê°€"
                            ).sort_index(ascending=False)
                            st.dataframe(pivot_df, use_container_width=True, height=800)
                        except Exception as e:
                            st.error(f"í”¼ë²— ìƒì„± ì˜¤ë¥˜: {e}")
                            st.dataframe(results_df)
