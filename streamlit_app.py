import streamlit as st
import pandas as pd
import plotly.graph_objs as go
import plotly.figure_factory as ff
import numpy as np
from scipy.stats import t

# í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
st.set_page_config(page_title="Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´ v1.0", layout="wide")
st.title("ğŸ“Š Dooch XRL(F) ì„±ëŠ¥ ê³¡ì„  ë·°ì–´ v1.0")

# --- ìœ í‹¸ë¦¬í‹° ë° ê¸°ë³¸ ë¶„ì„ í•¨ìˆ˜ë“¤ ---
SERIES_ORDER = ["XRF3", "XRF5", "XRF10", "XRF15", "XRF20", "XRF32", "XRF45", "XRF64", "XRF95", "XRF125", "XRF155", "XRF185", "XRF215", "XRF255"]

def get_best_match_column(df, names):
    if df is None or df.empty: return None
    for n in names:
        for col in df.columns:
            if n in col.strip():
                return col
    return None

def calculate_efficiency(df, q_col, h_col, k_col):
    if not all(col and col in df.columns for col in [q_col, h_col, k_col]): return df
    df_copy = df.copy()
    # Q(mÂ³/min), H(m) ê¸°ì¤€ ì¶•ë™ë ¥(kW) ê³„ì‚° ìƒìˆ˜ 0.163
    hydraulic_power = 0.163 * df_copy[q_col] * df_copy[h_col]
    shaft_power = df_copy[k_col]
    df_copy['Efficiency'] = np.where(shaft_power > 0, (hydraulic_power / shaft_power) * 100, 0)
    return df_copy

def load_sheet(uploaded_file, sheet_name):
    try:
        df = pd.read_excel(uploaded_file, sheet_name=sheet_name)
        df.columns = df.columns.str.strip()
        mcol = get_best_match_column(df, ["ëª¨ë¸ëª…", "ëª¨ë¸", "Model"])
        if not mcol: return None, pd.DataFrame()
        if 'Series' in df.columns: df = df.drop(columns=['Series'])
        df['Series'] = df[mcol].astype(str).str.extract(r"(XRF\d+)")
        df['Series'] = pd.Categorical(df['Series'], categories=SERIES_ORDER, ordered=True)
        df = df.sort_values('Series')
        return mcol, df
    except Exception:
        return None, pd.DataFrame()

def process_data(df, q_col, h_col, k_col):
    if df.empty: return df
    temp_df = df.copy()
    for col in [q_col, h_col, k_col]:
        if col and col in temp_df.columns:
            temp_df = temp_df.dropna(subset=[col])
            temp_df = temp_df[pd.to_numeric(temp_df[col], errors='coerce').notna()]
            temp_df[col] = pd.to_numeric(temp_df[col])
    return calculate_efficiency(temp_df, q_col, h_col, k_col)

def analyze_operating_point(df, models, target_q, target_h, m_col, q_col, h_col, k_col):
    if target_h <= 0: return pd.DataFrame()
    results = []

    if target_q == 0:
        for model in models:
            model_df = df[df[m_col] == model].sort_values(q_col)
            if model_df.empty: continue
            churn_h = model_df.iloc[0][h_col]
            if churn_h >= target_h:
                churn_kw = model_df.iloc[0][k_col] if k_col and k_col in model_df.columns else np.nan
                churn_eff = np.interp(0, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else 0
                results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": "0 (ì²´ì ˆ)", "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{churn_h:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{churn_kw:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{churn_eff:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})
        return pd.DataFrame(results)

    for model in models:
        model_df = df[df[m_col] == model].sort_values(q_col)
        if len(model_df) < 2 or not (model_df[q_col].min() <= target_q <= model_df[q_col].max()): continue
        interp_h = np.interp(target_q, model_df[q_col], model_df[h_col])
        
        if interp_h >= target_h:
            interp_kw = np.interp(target_q, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan
            interp_eff = np.interp(target_q, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else np.nan
            results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": target_q, "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{interp_h:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{interp_eff:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})
        else:
            h_values_rev = model_df[h_col].values[::-1]
            q_values_rev = model_df[q_col].values[::-1]

            if target_h <= model_df[h_col].max() and target_h >= model_df[h_col].min():
                q_required = np.interp(target_h, h_values_rev, q_values_rev)
                if 0.95 * target_q <= q_required < target_q:
                    correction_pct = (1 - (q_required / target_q)) * 100
                    status_text = f"ìœ ëŸ‰ {correction_pct:.1f}% ë³´ì • ì „ì œ ì‚¬ìš© ê°€ëŠ¥"
                    interp_kw_corr = np.interp(q_required, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan
                    interp_eff_corr = np.interp(q_required, model_df[q_col], model_df['Efficiency']) if 'Efficiency' in model_df.columns else np.nan
                    results.append({"ëª¨ë¸ëª…": model, "ìš”êµ¬ ìœ ëŸ‰": target_q, "ìš”êµ¬ ì–‘ì •": target_h, "ì˜ˆìƒ ì–‘ì •": f"{target_h:.2f} (at Q={q_required:.2f})", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw_corr:.2f}", "ì˜ˆìƒ íš¨ìœ¨(%)": f"{interp_eff_corr:.2f}", "ì„ ì • ê°€ëŠ¥": status_text})
    
    return pd.DataFrame(results)

def analyze_fire_pump_point(df, models, target_q, target_h, m_col, q_col, h_col, k_col):
    if target_q <= 0 or target_h <= 0: return pd.DataFrame()
    results = []
    for model in models:
        model_df = df[df[m_col] == model].sort_values(q_col)
        if len(model_df) < 2: continue
        
        interp_h_rated = np.interp(target_q, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)
        h_churn = model_df.iloc[0][h_col]
        q_overload = 1.5 * target_q
        interp_h_overload = np.interp(q_overload, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)

        if not np.isnan(interp_h_rated) and interp_h_rated >= target_h:
            cond1_ok = h_churn <= (1.40 * target_h)
            cond2_ok = (not np.isnan(interp_h_overload)) and (interp_h_overload >= (0.65 * target_h))
            if cond1_ok and cond2_ok:
                interp_kw = np.interp(target_q, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan
                results.append({"ëª¨ë¸ëª…": model, "ì •ê²© ì˜ˆìƒ ì–‘ì •": f"{interp_h_rated:.2f}", "ì²´ì ˆ ì–‘ì • (â‰¤{1.4*target_h:.2f})": f"{h_churn:.2f}", "ìµœëŒ€ìš´ì „ ì–‘ì • (â‰¥{0.65*target_h:.2f})": f"{interp_h_overload:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw:.2f}", "ì„ ì • ê°€ëŠ¥": "âœ…"})
                continue

        h_values_rev = model_df[h_col].values[::-1]
        q_values_rev = model_df[q_col].values[::-1]

        if target_h <= model_df[h_col].max() and target_h >= model_df[h_col].min():
            q_required = np.interp(target_h, h_values_rev, q_values_rev)
            if 0.95 * target_q <= q_required < target_q:
                q_overload_corr = 1.5 * q_required
                interp_h_overload_corr = np.interp(q_overload_corr, model_df[q_col], model_df[h_col], left=np.nan, right=np.nan)
                
                cond1_ok = h_churn <= (1.40 * target_h)
                cond2_ok = (not np.isnan(interp_h_overload_corr)) and (interp_h_overload_corr >= (0.65 * target_h))

                if cond1_ok and cond2_ok:
                    correction_pct = (1 - (q_required / target_q)) * 100
                    status_text = f"ìœ ëŸ‰ {correction_pct:.1f}% ë³´ì • ì „ì œ ì‚¬ìš© ê°€ëŠ¥"
                    interp_kw_corr = np.interp(q_required, model_df[q_col], model_df[k_col]) if k_col and k_col in model_df.columns else np.nan
                    results.append({"ëª¨ë¸ëª…": model, "ì •ê²© ì˜ˆìƒ ì–‘ì •": f"{target_h:.2f} (at Q={q_required:.2f})", "ì²´ì ˆ ì–‘ì • (â‰¤{1.4*target_h:.2f})": f"{h_churn:.2f}", "ìµœëŒ€ìš´ì „ ì–‘ì • (â‰¥{0.65*target_h:.2f})": f"{interp_h_overload_corr:.2f}", "ì˜ˆìƒ ë™ë ¥(kW)": f"{interp_kw_corr:.2f}", "ì„ ì • ê°€ëŠ¥": status_text})
    
    return pd.DataFrame(results)

def render_filters(df, mcol, prefix):
    if df is None or df.empty or mcol is None or 'Series' not in df.columns:
        st.warning("í•„í„°ë§í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()
    series_opts = df['Series'].dropna().unique().tolist()
    default_series = [series_opts[0]] if series_opts else []
    mode = st.radio("ë¶„ë¥˜ ê¸°ì¤€", ["ì‹œë¦¬ì¦ˆë³„", "ëª¨ë¸ë³„"], key=f"{prefix}_mode", horizontal=True)
    if mode == "ì‹œë¦¬ì¦ˆë³„":
        sel = st.multiselect("ì‹œë¦¬ì¦ˆ ì„ íƒ", series_opts, default=default_series, key=f"{prefix}_series")
        df_f = df[df['Series'].isin(sel)] if sel else pd.DataFrame()
    else:
        model_opts = df[mcol].dropna().unique().tolist()
        default_model = [model_opts[0]] if model_opts else []
        sel = st.multiselect("ëª¨ë¸ ì„ íƒ", model_opts, default=default_model, key=f"{prefix}_models")
        df_f = df[df[mcol].isin(sel)] if sel else pd.DataFrame()
    return df_f

def add_traces(fig, df, mcol, xcol, ycol, models, mode, line_style=None, name_suffix=""):
    for m in models:
        sub = df[df[mcol] == m].sort_values(xcol)
        if sub.empty or ycol not in sub.columns: continue
        fig.add_trace(go.Scatter(x=sub[xcol], y=sub[ycol], mode=mode, name=m + name_suffix, line=line_style or {}))

def add_bep_markers(fig, df, mcol, qcol, ycol, models):
    for m in models:
        model_df = df[df[mcol] == m]
        if not model_df.empty and 'Efficiency' in model_df.columns and not model_df['Efficiency'].isnull().all():
            bep_row = model_df.loc[model_df['Efficiency'].idxmax()]
            fig.add_trace(go.Scatter(x=[bep_row[qcol]], y=[bep_row[ycol]], mode='markers', marker=dict(symbol='star', size=15, color='gold'), name=f'{m} BEP'))

def add_guide_lines(fig, h_line, v_line):
    if h_line is not None and h_line > 0:
        fig.add_shape(type="line", x0=0, x1=1, xref="paper", y0=h_line, y1=h_line, yref="y", line=dict(color="gray", dash="dash"))
    if v_line is not None and v_line > 0:
        fig.add_shape(type="line", x0=v_line, x1=v_line, xref="x", y0=0, y1=1, yref="paper", line=dict(color="gray", dash="dash"))

def render_chart(fig, key):
    fig.update_layout(dragmode='pan', xaxis=dict(fixedrange=False), yaxis=dict(fixedrange=False), legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1))
    st.plotly_chart(fig, use_container_width=True, config={'scrollZoom': True, 'displaylogo': False}, key=key)

def perform_validation_analysis(df_r, df_d, m_r, m_d, q_r, q_d, y_r_col, y_d_col, test_id_col, models_to_validate, analysis_type):
    all_results = {}
    for model in models_to_validate:
        model_summary = []
        model_r_df = df_r[(df_r[m_r] == model) & (df_r[y_r_col].notna())].sort_values(by=q_r)
        model_d_df = df_d[(df_d[m_d] == model) & (df_d[y_d_col].notna())]
        if model_r_df.empty or model_d_df.empty: continue
        
        max_q = model_r_df[q_r].max()
        validation_q = np.linspace(0, max_q, 10)
        ref_y = np.interp(validation_q, model_r_df[q_r], model_r_df[y_r_col])
        test_ids = model_d_df[test_id_col].unique()
        interpolated_y_samples = {q: [] for q in validation_q}
        for test_id in test_ids:
            test_df = model_d_df[model_d_df[test_id_col] == test_id].sort_values(by=q_d)
            if len(test_df) < 2: continue
            interp_y = np.interp(validation_q, test_df[q_d], test_df[y_d_col])
            for i, q in enumerate(validation_q):
                interpolated_y_samples[q].append(interp_y[i])
        
        for i, q in enumerate(validation_q):
            samples = np.array(interpolated_y_samples[q])
            n = len(samples)
            base_col_name = f"ê¸°ì¤€ {analysis_type}"
            mean_col_name = "í‰ê· "
            if n < 2:
                model_summary.append({
                    "ëª¨ë¸ëª…": model, "ê²€ì¦ ìœ ëŸ‰(Q)": q, base_col_name: ref_y[i], 
                    "ì‹œí—˜ íšŸìˆ˜(n)": n, mean_col_name: np.nan, "í‘œì¤€í¸ì°¨": np.nan, 
                    "95% CI í•˜í•œ": np.nan, "95% CI ìƒí•œ": np.nan, "ìœ íš¨ì„±": "íŒë‹¨ë¶ˆê°€",
                    "_original_q": q
                })
                continue
            
            mean_y, std_dev = np.mean(samples), np.std(samples, ddof=1)
            std_err = std_dev / np.sqrt(n)
            t_critical = t.ppf(0.975, df=n-1)
            margin_of_error = t_critical * std_err
            ci_lower, ci_upper = mean_y - margin_of_error, mean_y + margin_of_error
            is_valid = "âœ… ìœ íš¨" if ci_lower <= ref_y[i] <= ci_upper else "âŒ ë²—ì–´ë‚¨"
            
            model_summary.append({
                "ëª¨ë¸ëª…": model, "ê²€ì¦ ìœ ëŸ‰(Q)": f"{q:.2f}", base_col_name: f"{ref_y[i]:.2f}",
                "ì‹œí—˜ íšŸìˆ˜(n)": n, mean_col_name: f"{mean_y:.2f}", "í‘œì¤€í¸ì°¨": f"{std_dev:.2f}",
                "95% CI í•˜í•œ": f"{ci_lower:.2f}", "95% CI ìƒí•œ": f"{ci_upper:.2f}", "ìœ íš¨ì„±": is_valid,
                "_original_q": q
            })
        
        all_results[model] = { 'summary': pd.DataFrame(model_summary), 'samples': interpolated_y_samples }
    return all_results

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â˜… [ìˆ˜ì •ë¨] parse_selection_table í•¨ìˆ˜ â˜…
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
def parse_selection_table(df_selection_table):
    """
    ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ 'XRF ëª¨ë¸ ì„ ì •í‘œ...' (CSV ë˜ëŠ” Excel) íŒŒì¼ì˜ íŠ¹ì • êµ¬ì¡°ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤.
    - Q (ìœ ëŸ‰)ì€ 11í–‰ (ì¸ë±ìŠ¤ 10)ì—ì„œ E, H, K... ì—´(3ì¹¸ ê°„ê²©)ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    - H (ì–‘ì •)ì€ Bì—´ (ì¸ë±ìŠ¤ 1)ì—ì„œ 16, 19, 22... í–‰(3ì¤„ ê°„ê²©)ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    - Modelì€ ìœ„ Q, Hê°€ êµì°¨í•˜ëŠ” ì§€ì ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    try:
        # ìœ ëŸ‰(Q) í—¤ë”ê°€ ìˆëŠ” ì—´ ì¸ë±ìŠ¤: 4(E), 7(H), 10(K), ...
        q_col_indices = list(range(4, df_selection_table.shape[1], 3))
        # ì–‘ì •(H) í—¤ë”ê°€ ìˆëŠ” í–‰ ì¸ë±ìŠ¤: 15(16í–‰), 18(19í–‰), 21(22í–‰), ...
        h_row_indices = list(range(15, df_selection_table.shape[0], 3))
        
        tasks = []
        q_values = {}
        h_values = {}

        # 1. ìœ ëŸ‰(Q) ê°’ íŒŒì‹± (11í–‰, ì¸ë±ìŠ¤ 10)
        # iloc[10, c_idx]ëŠ” ì—‘ì…€ ê¸°ì¤€ 11í–‰
        for c_idx in q_col_indices:
            q_val_raw = str(df_selection_table.iloc[10, c_idx])
            if pd.isna(q_val_raw) or q_val_raw == "": continue
            try:
                # '0.13 (7.8)' í˜•ì‹ì—ì„œ '0.13'ë§Œ ì¶”ì¶œ
                q_val_clean = q_val_raw.split('(')[0].strip()
                q_values[c_idx] = float(q_val_clean)
            except (ValueError, TypeError):
                continue # ìœ íš¨í•˜ì§€ ì•Šì€ ì—´ ìŠ¤í‚µ
        
        # 2. ì–‘ì •(H) ê°’ íŒŒì‹± (Bì—´, ì¸ë±ìŠ¤ 1)
        # iloc[r_idx, 1]ëŠ” ì—‘ì…€ ê¸°ì¤€ Bì—´
        for r_idx in h_row_indices:
            h_val_raw = str(df_selection_table.iloc[r_idx, 1])
            if pd.isna(h_val_raw) or h_val_raw == "": continue
            try:
                # [ìˆ˜ì •] '301\n(139.8)' ë˜ëŠ” '301 (139.8)' í˜•ì‹ì—ì„œ '301'ë§Œ ì¶”ì¶œ
                h_val_clean = h_val_raw.split('\n')[0].split('(')[0].strip()
                h_values[r_idx] = float(h_val_clean)
            except (ValueError, TypeError):
                continue # ìœ íš¨í•˜ì§€ ì•Šì€ í–‰ ìŠ¤í‚µ
        
        # 3. êµì°¨ ì§€ì ì˜ ëª¨ë¸ëª… íŒŒì‹±
        for r_idx in h_values:
            for c_idx in q_values:
                # iloc[r_idx, c_idx]ëŠ” ì—‘ì…€ ê¸°ì¤€ [16í–‰, Eì—´], [16í–‰, Hì—´]...
                model_name = str(df_selection_table.iloc[r_idx, c_idx]).strip()
                
                # 'nan', 'ë¯¸ì„ ì •...' ë“±ì´ ì•„ë‹Œ ìœ íš¨í•œ ëª¨ë¸ëª…ì¸ì§€ í™•ì¸
                if model_name and model_name.lower() != 'nan' and 'XRF' in model_name:
                    tasks.append({
                        "ëª¨ë¸ëª…": model_name,
                        "ìš”êµ¬ ìœ ëŸ‰ (Q)": q_values[c_idx],
                        "ìš”êµ¬ ì–‘ì • (H)": h_values[r_idx],
                        "_source_cell": f"[Row {r_idx + 1}, Col {chr(65 + c_idx)}]" # ë””ë²„ê¹…ìš©
                    })
        
        return pd.DataFrame(tasks)
    
    except Exception as e:
        st.error(f"ì„ ì •í‘œ íŒŒì‹± ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}. (ì—‘ì…€ í–‰/ì—´ êµ¬ì¡°ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)")
        return pd.DataFrame()
# â˜… (ìˆ˜ì • ë) â˜…
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

def display_validation_output(model, validation_data, analysis_type, df_r, df_d, m_r, m_d, q_r, q_d, y_r_col, y_d_col, test_id_col):
    if model not in validation_data or validation_data[model]['summary'].empty:
        st.warning(f"'{model}' ëª¨ë¸ì— ëŒ€í•œ {analysis_type} ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    model_data = validation_data[model]
    model_summary_df = model_data['summary']
    model_samples = model_data['samples']
    base_col_name = f"ê¸°ì¤€ {analysis_type}"
    
    st.markdown(f"#### ë¶„ì„ ê²°ê³¼ ìš”ì•½ ({analysis_type})")
    display_summary = model_summary_df.drop(columns=['_original_q']).set_index('ëª¨ë¸ëª…')
    st.dataframe(display_summary, use_container_width=True)
    
    st.markdown(f"#### ëª¨ë¸ë³„ ìƒì„¸ ê²°ê³¼ ì‹œê°í™” ({analysis_type})")
    fig_main = go.Figure()
    numeric_cols = ["ê²€ì¦ ìœ ëŸ‰(Q)", base_col_name, "95% CI í•˜í•œ", "95% CI ìƒí•œ"]
    for col in numeric_cols: model_summary_df[col] = pd.to_numeric(model_summary_df[col], errors='coerce')
    
    fig_main.add_trace(go.Scatter(x=model_summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=model_summary_df['95% CI ìƒí•œ'], fill=None, mode='lines', line_color='rgba(0,100,80,0.2)', name='95% CI ìƒí•œ'))
    fig_main.add_trace(go.Scatter(x=model_summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=model_summary_df['95% CI ìƒí•œ'], fill='tonexty', mode='lines', line_color='rgba(0,100,80,0.2)', name='95% CI í•˜í•œ'))
    
    model_d_df_vis = df_d[(df_d[m_d] == model) & (df_d[y_d_col].notna())]; test_ids_vis = model_d_df_vis[test_id_col].unique()
    for test_id in test_ids_vis:
        test_df_vis = model_d_df_vis[model_d_df_vis[test_id_col] == test_id].sort_values(by=q_d)
        fig_main.add_trace(go.Scatter(x=test_df_vis[q_d], y=test_df_vis[y_d_col], mode='lines', line=dict(width=1, color='grey'), name=f'ì‹œí—˜ {test_id}', opacity=0.5, showlegend=False))
    
    model_r_df_vis = df_r[(df_r[m_r] == model) & (df_r[y_r_col].notna())].sort_values(by=q_r)
    fig_main.add_trace(go.Scatter(x=model_r_df_vis[q_r], y=model_r_df_vis[y_r_col], mode='lines+markers', line=dict(color='blue', width=3), name='Reference Curve'))
    
    if analysis_type == 'ì–‘ì •':
        upper_limit = model_summary_df[base_col_name] * 1.05
        lower_limit = model_summary_df[base_col_name] * 0.95
        fig_main.add_trace(go.Scatter(x=model_summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=upper_limit, mode='lines', name='ì–‘ì • ìƒí•œ (+5%)', line=dict(color='orange', dash='dash')))
        fig_main.add_trace(go.Scatter(x=model_summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=lower_limit, mode='lines', name='ì–‘ì • í•˜í•œ (-5%)', line=dict(color='orange', dash='dash')))

    valid_points = model_summary_df[model_summary_df['ìœ íš¨ì„±'] == 'âœ… ìœ íš¨']; invalid_points = model_summary_df[model_summary_df['ìœ íš¨ì„±'] == 'âŒ ë²—ì–´ë‚¨']
    fig_main.add_trace(go.Scatter(x=valid_points['ê²€ì¦ ìœ ëŸ‰(Q)'], y=valid_points[base_col_name], mode='markers', marker=dict(color='green', size=10, symbol='circle'), name='ìœ íš¨ í¬ì¸íŠ¸'))
    fig_main.add_trace(go.Scatter(x=invalid_points['ê²€ì¦ ìœ ëŸ‰(Q)'], y=invalid_points[base_col_name], mode='markers', marker=dict(color='red', size=10, symbol='x'), name='ë²—ì–´ë‚¨ í¬ì¸íŠ¸'))
    
    fig_main.update_layout(yaxis_title=analysis_type)
    st.plotly_chart(fig_main, use_container_width=True)

    with st.expander(f"ê²€ì¦ ìœ ëŸ‰ ì§€ì ë³„ {analysis_type} ë°ì´í„° ë¶„í¬í‘œ ë³´ê¸°"):
        for idx, row in model_summary_df.iterrows():
            q_point_original = row['_original_q']
            samples = model_samples.get(q_point_original, [])
            if not samples or row['ì‹œí—˜ íšŸìˆ˜(n)'] < 2: continue
            q_point_str, ref_y_point, mean_y, std_y, n_samples = row['ê²€ì¦ ìœ ëŸ‰(Q)'], float(row[base_col_name]), float(row['í‰ê· ']), float(row['í‘œì¤€í¸ì°¨']), int(row['ì‹œí—˜ íšŸìˆ˜(n)'])
            st.markdown(f"**Q = {q_point_str}**")
            st.markdown(f"<small>í‰ê· : {mean_y:.2f} | í‘œì¤€í¸ì°¨: {std_y:.2f} | n: {n_samples}</small>", unsafe_allow_html=True)
            fig_dist = ff.create_distplot([samples], ['ì‹œí—˜ ë°ì´í„°'], show_hist=False, show_rug=True)
            fig_dist.add_vline(x=ref_y_point, line_width=2, line_dash="dash", line_color="red")
            fig_dist.add_vline(x=mean_y, line_width=2, line_dash="dot", line_color="blue")
            fig_dist.update_layout(title_text=None, xaxis_title=analysis_type, yaxis_title="ë°€ë„", height=300, margin=dict(l=20,r=20,t=5,b=20), showlegend=False)
            st.plotly_chart(fig_dist, use_container_width=True, config={'displayModeBar': False})
            st.markdown("---")

# --- ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ ë¡œì§ ---
uploaded_file = st.file_uploader("1. ê¸°ì¤€ ë°ì´í„° Excel íŒŒì¼ ì—…ë¡œë“œ (reference data ì‹œíŠ¸ í¬í•¨)", type=["xlsx", "xlsm"])
if uploaded_file:
    m_r, df_r_orig = load_sheet(uploaded_file, "reference data"); m_c, df_c_orig = load_sheet(uploaded_file, "catalog data"); m_d, df_d_orig = load_sheet(uploaded_file, "deviation data")
    if df_r_orig.empty: st.error("ì˜¤ë¥˜: 'reference data' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ 'ëª¨ë¸ëª…' ê´€ë ¨ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        st.sidebar.title("âš™ï¸ ë¶„ì„ ì„¤ì •"); st.sidebar.markdown("### Total íƒ­ & ìš´ì „ì  ë¶„ì„ ì»¬ëŸ¼ ì§€ì •")
        all_columns_r = df_r_orig.columns.tolist()
        def safe_get_index(items, value, default=0):
            try: return items.index(value)
            except (ValueError, TypeError): return default
        q_auto_r = get_best_match_column(df_r_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]); h_auto_r = get_best_match_column(df_r_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]); k_auto_r = get_best_match_column(df_r_orig, ["ì¶•ë™ë ¥"])
        q_col_total = st.sidebar.selectbox("ìœ ëŸ‰ (Flow) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, q_auto_r))
        h_col_total = st.sidebar.selectbox("ì–‘ì • (Head) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, h_auto_r))
        k_col_total = st.sidebar.selectbox("ì¶•ë™ë ¥ (Power) ì»¬ëŸ¼", all_columns_r, index=safe_get_index(all_columns_r, k_auto_r))
        q_c, h_c, k_c = (get_best_match_column(df_c_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]), get_best_match_column(df_c_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]), get_best_match_column(df_c_orig, ["ì¶•ë™ë ¥"]))
        q_d, h_d, k_d = (get_best_match_column(df_d_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]), get_best_match_column(df_d_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]), get_best_match_column(df_d_orig, ["ì¶•ë™ë ¥"]))
        test_id_col_d = get_best_match_column(df_d_orig, ["ì‹œí—˜ë²ˆí˜¸", "Test No", "Test ID"])
        if not df_d_orig.empty and test_id_col_d:
            df_d_orig[test_id_col_d] = df_d_orig[test_id_col_d].astype(str).str.strip()
            df_d_orig[test_id_col_d].replace(['', 'nan'], np.nan, inplace=True)
            df_d_orig[test_id_col_d] = df_d_orig[test_id_col_d].ffill()
        df_r = process_data(df_r_orig, q_col_total, h_col_total, k_col_total); df_c = process_data(df_c_orig, q_c, h_c, k_c); df_d = process_data(df_d_orig, q_d, h_d, k_d)
        
        # 'íƒ­ ë¦¬ìŠ¤íŠ¸' ìˆ˜ì • (ë§¨ ë’¤ì— "ğŸ”¥ ì„ ì •í‘œ ê²€í†  (AI)" ì¶”ê°€)
        tab_list = ["Total", "Reference", "Catalog", "Deviation", "Validation", "ğŸ”¥ ì„ ì •í‘œ ê²€í†  (AI)"]
        tabs = st.tabs(tab_list)
        
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… 'Total' íƒ­ (ì›ë³¸ ìœ ì§€) â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
        with tabs[0]:
            st.subheader("ğŸ“Š Total - í†µí•© ê³¡ì„  ë° ìš´ì „ì  ë¶„ì„")
            df_f = render_filters(df_r, m_r, "total")
            models = df_f[m_r].unique().tolist() if m_r and not df_f.empty else []
            
            with st.expander("ìš´ì „ì  ë¶„ì„ (Operating Point Analysis)"):
                st.markdown("#### ğŸ¯ ë‹¨ì¼ ìš´ì „ì  ê¸°ì¤€ ëª¨ë¸ ê²€ìƒ‰")
                analysis_mode = st.radio("ë¶„ì„ ëª¨ë“œ", ["ê¸°ê³„", "ì†Œë°©"], key="analysis_mode", horizontal=True)
                op_col1, op_col2 = st.columns(2)

                with op_col1:
                    q_input_str = st.text_input("ëª©í‘œ ìœ ëŸ‰ (Q, mÂ³/min)", value="0.0")
                    try:
                        target_q = float(q_input_str)
                    except ValueError:
                        target_q = 0.0
                        st.warning("ìœ ëŸ‰ì— ìœ íš¨í•œ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="âš ï¸")
                
                with op_col2:
                    h_input_str = st.text_input("ëª©í‘œ ì–‘ì • (H, m)", value="0.0")
                    try:
                        target_h = float(h_input_str)
                    except ValueError:
                        target_h = 0.0
                        st.warning("ì–‘ì •ì— ìœ íš¨í•œ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.", icon="âš ï¸")

                if analysis_mode == "ì†Œë°©": st.info("ì†Œë°© íŒí”„ ì„±ëŠ¥ ê¸°ì¤€ 3ì (ì •ê²©, ì²´ì ˆ, ìµœëŒ€)ì„ ìë™ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
                if st.button("ëª¨ë¸ ê²€ìƒ‰ ì‹¤í–‰"):
                    if not models: st.warning("ë¨¼ì € ë¶„ì„í•  ì‹œë¦¬ì¦ˆë‚˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
                    else:
                        with st.spinner("ì„ íƒëœ ëª¨ë¸ë“¤ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                            if analysis_mode == "ì†Œë°©": op_results_df = analyze_fire_pump_point(df_r, models, target_q, target_h, m_r, q_col_total, h_col_total, k_col_total)
                            else: op_results_df = analyze_operating_point(df_r, models, target_q, target_h, m_r, q_col_total, h_col_total, k_col_total)
                            
                            if not op_results_df.empty: st.success(f"ì´ {len(op_results_df)}ê°œì˜ ëª¨ë¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."); st.dataframe(op_results_df, use_container_width=True)
                            else: st.info("ìš”êµ¬ ì„±ëŠ¥ì„ ë§Œì¡±í•˜ëŠ” ëª¨ë¸ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                st.markdown("---")
                st.markdown("#### ğŸ“¥ ëª¨ë¸ë³„ ê°œë³„ ìš´ì „ì  ê²€í†  (Batch)")
                
                st.info("ì—‘ì…€ì—ì„œ 'ëª¨ë¸ëª… | ìœ ëŸ‰(mÂ³/min) | ì–‘ì •(m)' 3ê°œ ì—´ì„ ë³µì‚¬í•˜ì—¬ ì•„ë˜ í‘œì— ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.\ní–‰ ì¶”ê°€ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.")

                if 'batch_df' not in st.session_state:
                    st.session_state.batch_df = pd.DataFrame(
                        [{"ëª¨ë¸ëª…": "XRF5-16", "ìš”êµ¬ ìœ ëŸ‰ (Q)": 0.06, "ìš”êµ¬ ì–‘ì • (H)": 35.0, "ë¶„ì„ ëª¨ë“œ": "ê¸°ê³„"}],
                        columns=["ëª¨ë¸ëª…", "ìš”êµ¬ ìœ ëŸ‰ (Q)", "ìš”êµ¬ ì–‘ì • (H)", "ë¶„ì„ ëª¨ë“œ"]
                    )
                
                st.markdown("##### 1. ê²€í† í•  ë°ì´í„° ì…ë ¥ (ë¶™ì—¬ë„£ê¸°/ìˆ˜ì •)")
                edited_df = st.data_editor(
                    st.session_state.batch_df,
                    column_config={
                        "ëª¨ë¸ëª…": st.column_config.TextColumn("ëª¨ë¸ëª…", width="medium"),
                        "ìš”êµ¬ ìœ ëŸ‰ (Q)": st.column_config.NumberColumn("ìš”êµ¬ ìœ ëŸ‰ (Q, mÂ³/min)", format="%.3f", width="small"),
                        "ìš”êµ¬ ì–‘ì • (H)": st.column_config.NumberColumn("ìš”êµ¬ ì–‘ì • (H, m)", format="%.2f", width="small"),
                        "ë¶„ì„ ëª¨ë“œ": st.column_config.SelectboxColumn(
                            "ë¶„ì„ ëª¨ë“œ",
                            options=["ê¸°ê³„", "ì†Œë°©"],
                            required=True,
                            width="small"
                        )
                    },
                    use_container_width=True,
                    num_rows="dynamic",
                    key="batch_editor"
                )
                
                st.session_state.batch_df = edited_df

                st.markdown("##### 2. ë¶„ì„ ì‹¤í–‰")
                if st.button("ğŸš€ ê°œë³„ ëª¨ë¸ ê²€í†  ì‹¤í–‰"):
                    results = []
                    if df_r.empty:
                        st.error("Reference data (df_r)ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. íŒŒì¼ ì—…ë¡œë“œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                    elif edited_df.empty:
                        st.warning("ê²€í† í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í‘œì— ë°ì´í„°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    else:
                        with st.spinner("ê°œë³„ ëª¨ë¸ ê²€í†  ì¤‘..."):
                            for _, row in edited_df.iterrows():
                                model = row['ëª¨ë¸ëª…']
                                q = row['ìš”êµ¬ ìœ ëŸ‰ (Q)']
                                h = row['ìš”êµ¬ ì–‘ì • (H)']
                                mode = row['ë¶„ì„ ëª¨ë“œ']
                                
                                if not model or pd.isna(model):
                                    continue
                                
                                if model not in df_r[m_r].unique():
                                    results.append({
                                        'ëª¨ë¸ëª…': model, 'ìš”êµ¬ ìœ ëŸ‰ (Q)': q, 'ìš”êµ¬ ì–‘ì • (H)': h, 'ë¶„ì„ ëª¨ë“œ': mode,
                                        'ê²°ê³¼': 'âŒ ëª¨ë¸ ì—†ìŒ',
                                        'ìƒì„¸': 'Reference ë°ì´í„°ì— í•´ë‹¹ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.'
                                    })
                                    continue

                                if mode == "ì†Œë°©":
                                    op_result = analyze_fire_pump_point(df_r, [model], q, h, m_r, q_col_total, h_col_total, k_col_total)
                                else: # "ê¸°ê³„"
                                    op_result = analyze_operating_point(df_r, [model], q, h, m_r, q_col_total, h_col_total, k_col_total)
                                    
                                if not op_result.empty:
                                    status = op_result.iloc[0]['ì„ ì • ê°€ëŠ¥']
                                    head_col_name = 'ì •ê²© ì˜ˆìƒ ì–‘ì •' if mode == "ì†Œë°©" else 'ì˜ˆìƒ ì–‘ì •'
                                    eff_str = f" | ì˜ˆìƒ íš¨ìœ¨: {op_result.iloc[0]['ì˜ˆìƒ íš¨ìœ¨(%)']}" if 'ì˜ˆìƒ íš¨ìœ¨(%)' in op_result.columns else ""
                                    head_val = op_result.iloc[0].get(head_col_name, 'N/A')
                                    power_val = op_result.iloc[0].get('ì˜ˆìƒ ë™ë ¥(kW)', 'N/A')
                                    details = f"ì˜ˆìƒ ì–‘ì •: {head_val} | ì˜ˆìƒ ë™ë ¥: {power_val}{eff_str}"
                                        
                                    results.append({
                                        'ëª¨ë¸ëª…': model, 'ìš”êµ¬ ìœ ëŸ‰ (Q)': q, 'ìš”êµ¬ ì–‘ì • (H)': h, 'ë¶„ì„ ëª¨ë“œ': mode,
                                        'ê²°ê³¼': status,
                                        'ìƒì„¸': details
                                    })
                                else:
                                    results.append({
                                        'ëª¨ë¸ëª…': model, 'ìš”êµ¬ ìœ ëŸ‰ (Q)': q, 'ìš”êµ¬ ì–‘ì • (H)': h, 'ë¶„ì„ ëª¨ë“œ': mode,
                                        'ê²°ê³¼': 'âŒ ì‚¬ìš© ë¶ˆê°€',
                                        'ìƒì„¸': 'ìš”êµ¬ ì„±ëŠ¥ì„ ë§Œì¡±í•˜ëŠ” ìš´ì „ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                                    })
                            
                        st.session_state.batch_results_df = pd.DataFrame(results)
                        if 'batch_results_df' not in st.session_state or st.session_state.batch_results_df.empty:
                            st.info("ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")


                if 'batch_results_df' in st.session_state and not st.session_state.batch_results_df.empty:
                    st.markdown("##### 3. ë¶„ì„ ê²°ê³¼")
                    st.dataframe(st.session_state.batch_results_df.set_index('ëª¨ë¸ëª…'), use_container_width=True)

            with st.expander("ì°¨íŠ¸ ë³´ì¡°ì„  ì¶”ê°€"):
                g_col1, g_col2, g_col3 = st.columns(3)
                with g_col1: h_guide_h, v_guide_h = st.number_input("Q-H ìˆ˜í‰ì„ ", value=0.0), st.number_input("Q-H ìˆ˜ì§ì„ ", value=0.0)
                with g_col2: h_guide_k, v_guide_k = st.number_input("Q-kW ìˆ˜í‰ì„ ", value=0.0), st.number_input("Q-kW ìˆ˜ì§ì„ ", value=0.0)
                with g_col3: h_guide_e, v_guide_e = st.number_input("Q-Eff ìˆ˜í‰ì„ ", value=0.0), st.number_input("Q-Eff ìˆ˜ì§ì„ ", value=0.0)
            
            st.markdown("---")
            ref_show = st.checkbox("Reference í‘œì‹œ", value=True); cat_show = st.checkbox("Catalog í‘œì‹œ"); dev_show = st.checkbox("Deviation í‘œì‹œ")
            st.markdown(f"#### Q-H (ìœ ëŸ‰-{h_col_total})")
            fig_h = go.Figure()
            if ref_show and not df_f.empty: add_traces(fig_h, df_f, m_r, q_col_total, h_col_total, models, 'lines+markers'); add_bep_markers(fig_h, df_f, m_r, q_col_total, h_col_total, models)
            if cat_show and not df_c.empty: add_traces(fig_h, df_c, m_c, q_c, h_c, models, 'lines+markers', line_style=dict(dash='dot'))
            if dev_show and not df_d.empty: add_traces(fig_h, df_d, m_d, q_d, h_d, models, 'markers')
            
            if 'target_q' in locals() and target_q > 0 and target_h > 0:
                fig_h.add_trace(go.Scatter(x=[target_q], y=[target_h], mode='markers', marker=dict(symbol='cross', size=15, color='magenta'), name='ì •ê²© ìš´ì „ì  (ë‹¨ì¼)'))
                if analysis_mode == "ì†Œë°©":
                    churn_h_limit = 1.4 * target_h; fig_h.add_trace(go.Scatter(x=[0], y=[churn_h_limit], mode='markers', marker=dict(symbol='x', size=12, color='red'), name=f'ì²´ì ˆì  ìƒí•œ'))
                    overload_q, overload_h_limit = 1.5 * target_q, 0.65 * target_h; fig_h.add_trace(go.Scatter(x=[overload_q], y=[overload_h_limit], mode='markers', marker=dict(symbol='diamond-open', size=12, color='blue'), name=f'ìµœëŒ€ì  í•˜í•œ'))
            
            if 'batch_results_df' in st.session_state and not st.session_state.batch_results_df.empty:
                batch_plot_df = st.session_state.batch_results_df
                fig_h.add_trace(go.Scatter(
                    x=batch_plot_df['ìš”êµ¬ ìœ ëŸ‰ (Q)'], 
                    y=batch_plot_df['ìš”êµ¬ ì–‘ì • (H)'],
                    mode='markers+text',
                    marker=dict(symbol='star', size=12, color='orange'),
                    text=batch_plot_df['ëª¨ë¸ëª…'] + " (" + batch_plot_df['ê²°ê³¼'] + ")",
                    textposition="top right",
                    name='ê°œë³„ ê²€í†  ìš´ì „ì '
                ))

            add_guide_lines(fig_h, h_guide_h, v_guide_h); render_chart(fig_h, "total_qh")
            
            st.markdown("#### Q-kW (ìœ ëŸ‰-ì¶•ë™ë ¥)"); fig_k = go.Figure()
            if ref_show and not df_f.empty: add_traces(fig_k, df_f, m_r, q_col_total, k_col_total, models, 'lines+markers')
            if cat_show and not df_c.empty: add_traces(fig_k, df_c, m_c, q_c, k_c, models, 'lines+markers', line_style=dict(dash='dot'))
            if dev_show and not df_d.empty: add_traces(fig_k, df_d, m_d, q_d, k_d, models, 'markers')
            add_guide_lines(fig_k, h_guide_k, v_guide_k); render_chart(fig_k, "total_qk")
            
            st.markdown("#### Q-Efficiency (ìœ ëŸ‰-íš¨ìœ¨)"); fig_e = go.Figure()
            if ref_show and not df_f.empty: add_traces(fig_e, df_f, m_r, q_col_total, 'Efficiency', models, 'lines+markers'); add_bep_markers(fig_e, df_f, m_r, q_col_total, 'Efficiency', models)
            if cat_show and not df_c.empty: add_traces(fig_e, df_c, m_c, q_c, 'Efficiency', models, 'lines+markers', line_style=dict(dash='dot'))
            if dev_show and not df_d.empty: add_traces(fig_e, df_d, m_d, q_d, 'Efficiency', models, 'markers')
            add_guide_lines(fig_e, h_guide_e, v_guide_e); render_chart(fig_e, "total_qe")
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜… 'Total' íƒ­ ë â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

        for idx, sheet_name in enumerate(["Reference", "Catalog", "Deviation"]):
            with tabs[idx+1]:
                st.subheader(f"ğŸ“Š {sheet_name} Data")
                df, mcol, df_orig = (df_r, m_r, df_r_orig) if sheet_name == "Reference" else (df_c, m_c, df_c_orig) if sheet_name == "Catalog" else (df_d, m_d, df_d_orig)
                if df.empty: st.info(f"'{sheet_name.lower()}' ì‹œíŠ¸ì˜ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."); continue
                q_col_tab = get_best_match_column(df_orig, ["í† ì¶œëŸ‰", "ìœ ëŸ‰"]); h_col_tab = get_best_match_column(df_orig, ["í† ì¶œì–‘ì •", "ì „ì–‘ì •"]); k_col_tab = get_best_match_column(df_orig, ["ì¶•ë™ë ¥"])
                df_f_tab = render_filters(df, mcol, sheet_name)
                models_tab = df_f_tab[mcol].unique().tolist() if not df_f_tab.empty else []
                if not models_tab: st.info("ì°¨íŠ¸ë¥¼ ë³´ë ¤ë©´ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”."); continue
                mode, style = ('markers', None) if sheet_name == "Deviation" else ('lines+markers', dict(dash='dot') if sheet_name == "Catalog" else None)
                if h_col_tab: st.markdown(f"#### Q-H ({h_col_tab})"); fig1 = go.Figure(); add_traces(fig1, df_f_tab, mcol, q_col_tab, h_col_tab, models_tab, mode, line_style=style); render_chart(fig1, key=f"{sheet_name}_qh")
                if k_col_tab in df_f_tab.columns: st.markdown("#### Q-kW (ì¶•ë™ë ¥)"); fig2 = go.Figure(); add_traces(fig2, df_f_tab, mcol, q_col_tab, k_col_tab, models_tab, mode, line_style=style); render_chart(fig2, key=f"{sheet_name}_qk")
                if 'Efficiency' in df_f_tab.columns: st.markdown("#### Q-Efficiency (íš¨ìœ¨)"); fig3 = go.Figure(); add_traces(fig3, df_f_tab, mcol, q_col_tab, 'Efficiency', models_tab, mode, line_style=style); fig3.update_layout(yaxis_title="íš¨ìœ¨ (%)", yaxis=dict(range=[0, 100])); render_chart(fig3, key=f"{sheet_name}_qe")
                st.markdown("#### ë°ì´í„° í™•ì¸"); st.dataframe(df_f_tab, use_container_width=True)
        
        with tabs[4]:
            st.subheader("ğŸ”¬ Reference Data í†µê³„ì  ìœ íš¨ì„± ê²€ì¦")
            power_cols_exist = k_col_total and k_d
            if not power_cols_exist: st.info("ì¶•ë™ë ¥ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” Referenceì™€ Deviation ì‹œíŠ¸ ì–‘ìª½ì— 'ì¶•ë™ë ¥' ê´€ë ¨ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            if df_d_orig.empty or test_id_col_d is None: st.warning("ìœ íš¨ì„± ê²€ì¦ì„ ìœ„í•´ 'deviation data' ì‹œíŠ¸ì™€ 'ì‹œí—˜ë²ˆí˜¸' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            else:
                with st.expander("Deviation ë°ì´í„° í™•ì¸í•˜ê¸°"): st.dataframe(df_d_orig)
                common_models = sorted(list(set(df_r[m_r].unique()) & set(df_d[m_d].unique())))
                if not common_models: st.info("Referenceì™€ Deviation ë°ì´í„°ì— ê³µí†µìœ¼ë¡œ ì¡´ì¬í•˜ëŠ” ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    models_to_validate = st.multiselect("ê²€ì¦í•  ëª¨ë¸ ì„ íƒ", common_models, default=common_models[:1])
                    if st.button("ğŸ“ˆ í†µê³„ ê²€ì¦ ì‹¤í–‰"):
                        with st.spinner("í†µê³„ ë¶„ì„ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                            head_results = perform_validation_analysis(df_r, df_d, m_r, m_d, q_col_total, q_d, h_col_total, h_d, test_id_col_d, models_to_validate, "ì–‘ì •")
                            if power_cols_exist: power_results = perform_validation_analysis(df_r, df_d, m_r, m_d, q_col_total, q_d, k_col_total, k_d, test_id_col_d, models_to_validate, "ì¶•ë™ë ¥")
                        st.success("í†µê³„ ë¶„ì„ ì™„ë£Œ!")
                        for model in models_to_validate:
                            st.markdown("---"); st.markdown(f"### ëª¨ë¸: {model}")
                            col1, col2 = st.columns(2)
                            with col1:
                                st.subheader("ğŸ“ˆ ì–‘ì •(Head) ìœ íš¨ì„± ê²€ì¦")
                                display_validation_output(model, head_results, "ì–‘ì •", df_r, df_d, m_r, m_d, q_col_total, q_d, h_col_total, h_d, test_id_col_d)
                            with col2:
                                if power_cols_exist:
                                    st.subheader("âš¡ ì¶•ë™ë ¥(Power) ìœ íš¨ì„± ê²€ì¦")
                                    display_validation_output(model, power_results, "ì¶•ë™ë ¥", df_r, df_d, m_r, m_d, q_col_total, q_d, k_col_total, k_d, test_id_col_d)
                        st.markdown("---"); st.header("ğŸ“Š í‘œì¤€ì„±ëŠ¥ ê³¡ì„  ì œì•ˆ (Reference vs. ì‹¤ì¸¡ í‰ê· )")
                        fig_col1, fig_col2 = st.columns(2)
                        with fig_col1:
                            st.subheader("Q-H Curve (ì–‘ì •)")
                            fig_h_proposal = go.Figure()
                            for model in models_to_validate:
                                if model in head_results and not head_results[model]['summary'].empty:
                                    summary_df = head_results[model]['summary']
                                    summary_df['í‰ê· '] = pd.to_numeric(summary_df['í‰ê· '], errors='coerce')
                                    fig_h_proposal.add_trace(go.Scatter(x=summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=summary_df['í‰ê· '], mode='lines+markers', name=f'{model} (ì œì•ˆ)'))
                                    model_r_df = df_r[df_r[m_r] == model].sort_values(q_col_total)
                                    fig_h_proposal.add_trace(go.Scatter(x=model_r_df[q_col_total], y=model_r_df[h_col_total], mode='lines', name=f'{model} (ê¸°ì¡´)', line=dict(dash='dot'), opacity=0.7))
                            st.plotly_chart(fig_h_proposal, use_container_width=True)
                        with fig_col2:
                            if power_cols_exist:
                                st.subheader("Q-kW Curve (ì¶•ë™ë ¥)")
                                fig_k_proposal = go.Figure()
                                for model in models_to_validate:
                                    if model in power_results and not power_results[model]['summary'].empty:
                                        summary_df = power_results[model]['summary']
                                        summary_df['í‰ê· '] = pd.to_numeric(summary_df['í‰ê· '], errors='coerce')
                                        fig_k_proposal.add_trace(go.Scatter(x=summary_df['ê²€ì¦ ìœ ëŸ‰(Q)'], y=summary_df['í‰ê· '], mode='lines+markers', name=f'{model} (ì œì•ˆ)'))
                                        model_r_df = df_r[df_r[m_r] == model].sort_values(q_col_total)
                                        fig_k_proposal.add_trace(go.Scatter(x=model_r_df[q_col_total], y=model_r_df[k_col_total], mode='lines', name=f'{model} (ê¸°ì¡´)', line=dict(dash='dot'), opacity=0.7))
                                st.plotly_chart(fig_k_proposal, use_container_width=True)

        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
        # â˜… 3. 'ì„ ì •í‘œ ê²€í†  (AI)' íƒ­ ë¡œì§ (ì‹ ê·œ ì¶”ê°€) â˜…
        # â˜…   (ì‹œíŠ¸ ì´ë¦„ 'XRF ëª¨ë¸ ì„ ì •í‘œ_í’ˆì§ˆê²€í† ë³¸_20250110'ì„ ë¨¼ì € ì‹œë„í•˜ë„ë¡ ìˆ˜ì •ë¨) â˜…
        # â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
        with tabs[5]:
            st.subheader("ğŸ”¥ XRF ëª¨ë¸ ì„ ì •í‘œ ìë™ ê²€í†  (AI)")
            st.warning("ì´ ê¸°ëŠ¥ì€ 'reference data'ê°€ (ì²«ë²ˆì§¸ ì—…ë¡œë“œë¡œ) ì •ìƒ ë¡œë“œë˜ì—ˆì„ ë•Œë§Œ ë™ì‘í•©ë‹ˆë‹¤.")
            
            # (1) ê¸°ì¤€ ë°ì´í„°(df_r)ê°€ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
            if df_r.empty or m_r is None:
                st.error("ê°€ì¥ ë¨¼ì € 'reference data'ê°€ í¬í•¨ëœ ì›ë³¸ Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤.")
            
            # (2) ê¸°ì¤€ ë°ì´í„°ê°€ ìˆì„ ê²½ìš°, ê²€í†  íŒŒì¼ ì—…ë¡œë” í‘œì‹œ
            else:
                st.info("ê²€í†  ëŒ€ìƒì¸ 'XRF ëª¨ë¸ ì„ ì •í‘œ...' ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
                
                review_excel_file = st.file_uploader("2. ì„ ì •í‘œ Excel íŒŒì¼ ì—…ë¡œë“œ (.xlsx, .xlsm)", type=["xlsx", "xlsm"], key="review_excel")
                
                if review_excel_file:
                    
                    # [ìˆ˜ì •] ì‚¬ìš©ìê°€ ì–¸ê¸‰í•œ íŠ¹ì • ì‹œíŠ¸ ì´ë¦„ì„ ë¨¼ì € ì‹œë„í•©ë‹ˆë‹¤.
                    sheet_to_try = 'XRF ëª¨ë¸ ì„ ì •í‘œ_í’ˆì§ˆê²€í† ë³¸_20250110'
                    try:
                        df_selection_excel = pd.read_excel(review_excel_file, sheet_name=sheet_to_try, header=None)
                        st.success(f"'{sheet_to_try}' ì‹œíŠ¸ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                    except Exception:
                        st.warning(f"'{sheet_to_try}' ì‹œíŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì—‘ì…€ íŒŒì¼ì˜ ì²« ë²ˆì§¸ ì‹œíŠ¸ë¥¼ ëŒ€ì‹  ì½ìŠµë‹ˆë‹¤.")
                        try:
                            # íŠ¹ì • ì‹œíŠ¸ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ì‹œíŠ¸ë¡œ Fallback
                            df_selection_excel = pd.read_excel(review_excel_file, sheet_name=0, header=None)
                            st.info("ì²« ë²ˆì§¸ ì‹œíŠ¸ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
                        except Exception as e_first:
                            st.error(f"Excel íŒŒì¼ ë¡œë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e_first}")
                            df_selection_excel = None

                    if df_selection_excel is not None:
                        # (3) ì—‘ì…€ íŒŒì‹± (ê¸°ì¡´ parse_selection_table í•¨ìˆ˜ ì¬ì‚¬ìš©)
                        if 'task_list_df' not in st.session_state or st.session_state.get('review_file_name') != review_excel_file.name:
                            with st.spinner("ì„ ì •í‘œ(Excel) íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ê²€í†  ëª©ë¡ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
                                st.session_state.task_list_df = parse_selection_table(df_selection_excel)
                                st.session_state.review_file_name = review_excel_file.name # ìƒˆ íŒŒì¼ ê°ì§€ìš©
                        
                        task_df = st.session_state.task_list_df
                        
                        if task_df.empty:
                            st.error("Excel íŒŒì¼ì—ì„œ ìœ íš¨í•œ ê²€í†  ëŒ€ìƒ(ëª¨ë¸ëª…, Q, H)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì´ë‚˜ ì‹œíŠ¸ ì´ë¦„ì„ í™•ì¸í•˜ì„¸ìš”.")
                        else:
                            st.markdown(f"**ì´ {len(task_df)}ê°œ**ì˜ ê²€í†  ëŒ€ìƒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                            with st.expander("íŒŒì‹±ëœ ê²€í†  ëª©ë¡ í™•ì¸ (Excel íŒŒì¼ ê¸°ì¤€)"):
                                st.dataframe(task_df, use_container_width=True)

                            # (4) ê²€í†  ì‹¤í–‰ ë²„íŠ¼
                            if st.button("ğŸš€ ì†Œë°© ì„±ëŠ¥ ê¸°ì¤€ ê²€í†  ì‹¤í–‰"):
                                with st.spinner(f"{len(task_df)}ê°œ í•­ëª©ì„ 'reference data'ì™€ ë¹„êµ ê²€í†  ì¤‘ì…ë‹ˆë‹¤... (1~2ë¶„ ì†Œìš”)"):
                                    results = []
                                    all_ref_models = df_r[m_r].unique() # ëª¨ë¸ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ìš© (ë¹ ë¥¸ ì†ë„)
                                    
                                    for _, row in task_df.iterrows():
                                        model = row['ëª¨ë¸ëª…']
                                        q = row['ìš”êµ¬ ìœ ëŸ‰ (Q)']
                                        h = row['ìš”êµ¬ ì–‘ì • (H)']
                                        
                                        # ê¸°ì¤€ ë°ì´í„°(df_r)ì— ëª¨ë¸ì´ ì—†ëŠ” ê²½ìš°
                                        if model not in all_ref_models:
                                            result_detail = {
                                                "ê²°ê³¼": "âŒ ëª¨ë¸ ì—†ìŒ",
                                                "ìƒì„¸": "Reference ë°ì´í„°ì— í•´ë‹¹ ëª¨ë¸ëª…ì´ ì—†ìŠµë‹ˆë‹¤."
                                            }
                                        else:
                                            # ì†Œë°© ì„±ëŠ¥ ë¶„ì„ ì‹¤í–‰
                                            op_result_df = analyze_fire_pump_point(df_r, [model], q, h, m_r, q_col_total, h_col_total, k_col_total)
                                            
                                            if not op_result_df.empty:
                                                # ë¶„ì„ ì„±ê³µ (ê¸°ì¤€ í†µê³¼)
                                                res_row = op_result_df.iloc[0]
                                                result_detail = {
                                                    "ê²°ê³¼": res_row['ì„ ì • ê°€ëŠ¥'], # "âœ…" ë˜ëŠ” "ìœ ëŸ‰ X% ë³´ì •..."
                                                    "ì •ê²© ì–‘ì •": res_row['ì •ê²© ì˜ˆìƒ ì–‘ì •'],
                                                    "ì²´ì ˆ ì–‘ì •": res_row[f'ì²´ì ˆ ì–‘ì • (â‰¤{1.4*h:.2f})'],
                                                    "ìµœëŒ€ ì–‘ì •": res_row[f'ìµœëŒ€ìš´ì „ ì–‘ì • (â‰¥{0.65*h:.2f})'],
                                                    "ì˜ˆìƒ ë™ë ¥": res_row['ì˜ˆìƒ ë™ë ¥(kW)']
                                                }
                                            else:
                                                # ë¶„ì„ ì‹¤íŒ¨ (ëª¨ë¸ì€ ìˆìœ¼ë‚˜ 3ì  ê¸°ì¤€ ë¯¸ë‹¬ ë˜ëŠ” ìœ ëŸ‰ ë²”ìœ„ ì´íƒˆ)
                                                # 'ê¸°ê³„' ëª¨ë“œë¡œ ë‹¨ìˆœ ì²´í¬í•˜ì—¬ íŒíŠ¸ ì œê³µ
                                                mech_check_df = analyze_operating_point(df_r, [model], q, h, m_r, q_col_total, h_col_total, k_col_total)
                                                if not mech_check_df.empty:
                                                    details = f"ì •ê²©ì ì€ ë§Œì¡±í•˜ë‚˜ 3ì (ì²´ì ˆ/ìµœëŒ€) ê¸°ì¤€ ë¯¸ë‹¬. (ì˜ˆìƒì–‘ì •: {mech_check_df.iloc[0]['ì˜ˆìƒ ì–‘ì •']})"
                                                else:
                                                    details = "ìš”êµ¬ ì„±ëŠ¥ì„ ë§Œì¡±í•˜ëŠ” ìš´ì „ì ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (ìœ ëŸ‰ ë²”ìœ„ ì´íƒˆ ë“±)"
                                                    
                                                result_detail = {
                                                    "ê²°ê³¼": "âŒ ì‚¬ìš© ë¶ˆê°€",
                                                    "ìƒì„¸": details
                                                }
                                    
                                        base_info = {
                                            "ì„ ì • ëª¨ë¸": model,
                                            "ìš”êµ¬ ìœ ëŸ‰(Q)": q,
                                            "ìš”êµ¬ ì–‘ì •(H)": h
                                        }
                                        base_info.update(result_detail)
                                        results.append(base_info)
                                    
                                st.session_state.review_results_df = pd.DataFrame(results)
                                st.success("ì„ ì •í‘œ ê²€í†  ì™„ë£Œ!")

                # (5) ê²°ê³¼ í‘œì‹œ
                if 'review_results_df' in st.session_state:
                    st.markdown("---")
                    st.markdown("### ğŸ“Š ê²€í†  ê²°ê³¼ ìš”ì•½")
                    results_df = st.session_state.review_results_df
                    
                    # ê²°ê³¼ í•„í„°ë§
                    failed_df = results_df[results_df['ê²°ê³¼'].str.contains("âŒ")]
                    warning_df = results_df[~results_df['ê²°ê³¼'].str.contains("âŒ|âœ…")] # "ë³´ì •" ë“±
                    success_df = results_df[results_df['ê²°ê³¼'] == "âœ…"]
                    
                    res_col1, res_col2, res_col3, res_col4 = st.columns(4)
                    res_col1.metric("ì´ ê²€í†  í•­ëª©", len(results_df))
                    res_col2.metric("âŒ ì„ ì • ì˜¤ë¥˜", len(failed_df), delta_color="inverse")
                    res_col3.metric("âš ï¸ ë³´ì • í•„ìš”", len(warning_df), delta_color="off")
                    res_col4.metric("âœ… ì„ ì • ê°€ëŠ¥", len(success_df))
                    
                    st.markdown("#### âŒ ì„ ì • ì˜¤ë¥˜ ëª©ë¡")
                    if failed_df.empty:
                        st.info("ì„ ì • ì˜¤ë¥˜ë¡œ íŒë‹¨ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.dataframe(failed_df.set_index("ì„ ì • ëª¨ë¸"), use_container_width=True)
                    
                    st.markdown("#### âš ï¸ ë³´ì • í•„ìš” ëª©ë¡")
                    if warning_df.empty:
                        st.info("ìœ ëŸ‰ ë³´ì •ì´ í•„ìš”í•œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.dataframe(warning_df.set_index("ì„ ì • ëª¨ë¸"), use_container_width=True)
                        
                    with st.expander("âœ… ì „ì²´ ê²€í†  ê²°ê³¼ ë³´ê¸° (ì„±ê³µ/ì‹¤íŒ¨/ë³´ì • í¬í•¨)"):
                        st.dataframe(results_df.set_index("ì„ ì • ëª¨ë¸"), use_container_width=True)
